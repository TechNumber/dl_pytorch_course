{
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "MRuSrP7JQ00i",
    "1b95Z8u7Q3OL"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "gpuClass": "standard"
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Разбор практики 1.**"
   ],
   "metadata": {
    "id": "RQ8rTFmQ0ueR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Задача 2**. Cделать нейрон, соответствующий оператору НЕ."
   ],
   "metadata": {
    "id": "9P9bWaC9QQJm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Neuron(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc = torch.nn.Linear(1, 1, bias=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
   ],
   "metadata": {
    "id": "Hh8sSJkEWNmT",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.257425Z",
     "iopub.execute_input": "2022-12-08T15:49:29.257800Z",
     "iopub.status.idle": "2022-12-08T15:49:29.264537Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.257769Z",
     "shell.execute_reply": "2022-12-08T15:49:29.263439Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "neuron = Neuron()\n",
    "neuron.fc.weight, neuron.fc.bias"
   ],
   "metadata": {
    "id": "r9HoH1koVQXi",
    "outputId": "e3020bb5-04c1-45cf-937a-77d6c2337325",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.271340Z",
     "iopub.execute_input": "2022-12-08T15:49:29.271674Z",
     "iopub.status.idle": "2022-12-08T15:49:29.286216Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.271647Z",
     "shell.execute_reply": "2022-12-08T15:49:29.285205Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[-0.4746]], requires_grad=True),\n Parameter containing:\n tensor([0.8451], requires_grad=True))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "neuron.fc.weight.data = torch.tensor([[-1.0]])\n",
    "neuron.fc.bias.data = torch.tensor([1.0])\n",
    "neuron.fc.weight, neuron.fc.bias"
   ],
   "metadata": {
    "id": "MLmGhtWFTYlV",
    "outputId": "9ca8cb0a-4683-44d6-e910-69e6908a587c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.288588Z",
     "iopub.execute_input": "2022-12-08T15:49:29.289075Z",
     "iopub.status.idle": "2022-12-08T15:49:29.297482Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.289012Z",
     "shell.execute_reply": "2022-12-08T15:49:29.296494Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[-1.]], requires_grad=True),\n Parameter containing:\n tensor([1.], requires_grad=True))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([0.0])\n",
    "neuron(x)"
   ],
   "metadata": {
    "id": "UFr5InkDTf-r",
    "outputId": "6504e778-9bd4-4c5f-c2f8-67d22bb522d5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.299226Z",
     "iopub.execute_input": "2022-12-08T15:49:29.300040Z",
     "iopub.status.idle": "2022-12-08T15:49:29.326185Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.299987Z",
     "shell.execute_reply": "2022-12-08T15:49:29.325165Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0])\n",
    "neuron(x)"
   ],
   "metadata": {
    "id": "sXJqgPEwAwHa",
    "outputId": "12c3a893-da2c-4b19-de63-0a803b132b38",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.327811Z",
     "iopub.execute_input": "2022-12-08T15:49:29.328162Z",
     "iopub.status.idle": "2022-12-08T15:49:29.335790Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.328128Z",
     "shell.execute_reply": "2022-12-08T15:49:29.334756Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Задача 3**. Cделать нейрон, соответствующий оператору И."
   ],
   "metadata": {
    "id": "TRxJxcRJQsMz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Neuron(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc = torch.nn.Linear(2, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
   ],
   "metadata": {
    "id": "7dvDtA7HX3V6",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.338655Z",
     "iopub.execute_input": "2022-12-08T15:49:29.339468Z",
     "iopub.status.idle": "2022-12-08T15:49:29.346407Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.339434Z",
     "shell.execute_reply": "2022-12-08T15:49:29.344939Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "neuron = Neuron()\n",
    "neuron.fc.weight, neuron.fc.bias"
   ],
   "metadata": {
    "id": "olMqAnQtX5NQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d3b3ffe4-f637-4338-a46f-9db503a316ab",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.347872Z",
     "iopub.execute_input": "2022-12-08T15:49:29.348825Z",
     "iopub.status.idle": "2022-12-08T15:49:29.358885Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.348702Z",
     "shell.execute_reply": "2022-12-08T15:49:29.357585Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[ 0.1956, -0.2291]], requires_grad=True),\n Parameter containing:\n tensor([0.0592], requires_grad=True))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "neuron.fc.weight.data = torch.tensor([[1.0, 1.0]])\n",
    "neuron.fc.bias.data = torch.tensor([-1.5])\n",
    "neuron.fc.weight, neuron.fc.bias"
   ],
   "metadata": {
    "id": "kAtwMX7HQ0aj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "53bb0196-ecaf-489c-858e-c3d420d454aa",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.360543Z",
     "iopub.execute_input": "2022-12-08T15:49:29.361361Z",
     "iopub.status.idle": "2022-12-08T15:49:29.371965Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.361328Z",
     "shell.execute_reply": "2022-12-08T15:49:29.371075Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[1., 1.]], requires_grad=True),\n Parameter containing:\n tensor([-1.5000], requires_grad=True))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([0.0, 0.0])\n",
    "neuron(x)"
   ],
   "metadata": {
    "id": "P27EdNkrXloh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "96718328-9f63-41df-8077-3791a2d6b905",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.373387Z",
     "iopub.execute_input": "2022-12-08T15:49:29.374520Z",
     "iopub.status.idle": "2022-12-08T15:49:29.381911Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.374485Z",
     "shell.execute_reply": "2022-12-08T15:49:29.380895Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0, 0.0 ])\n",
    "neuron(x)"
   ],
   "metadata": {
    "outputId": "c04b6405-d7ae-4e49-a6c1-6f478572f17a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BJc_ipGrei3",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.383427Z",
     "iopub.execute_input": "2022-12-08T15:49:29.384538Z",
     "iopub.status.idle": "2022-12-08T15:49:29.392046Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.384451Z",
     "shell.execute_reply": "2022-12-08T15:49:29.390993Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([0.0, 1.0 ])\n",
    "neuron(x)"
   ],
   "metadata": {
    "outputId": "2788282c-a684-43c1-f219-3d16f45f14d3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjVTdBf-rei5",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.393448Z",
     "iopub.execute_input": "2022-12-08T15:49:29.394196Z",
     "iopub.status.idle": "2022-12-08T15:49:29.402365Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.394163Z",
     "shell.execute_reply": "2022-12-08T15:49:29.401421Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0, 1.0 ])\n",
    "neuron(x)"
   ],
   "metadata": {
    "outputId": "9b335917-e009-479c-e75d-9d1565422b8e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyomxCJUrei5",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.408310Z",
     "iopub.execute_input": "2022-12-08T15:49:29.409211Z",
     "iopub.status.idle": "2022-12-08T15:49:29.416929Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.409168Z",
     "shell.execute_reply": "2022-12-08T15:49:29.415975Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Задача 4**. Cделать нейрон, соответствующий оператору ИЛИ."
   ],
   "metadata": {
    "id": "MRuSrP7JQ00i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "neuron.fc.weight.data = torch.tensor([[1., 1.]])\n",
    "neuron.fc.bias.data = torch.tensor([-0.5])"
   ],
   "metadata": {
    "id": "23RuhFqbQ24-",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.418412Z",
     "iopub.execute_input": "2022-12-08T15:49:29.419719Z",
     "iopub.status.idle": "2022-12-08T15:49:29.425364Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.419589Z",
     "shell.execute_reply": "2022-12-08T15:49:29.424356Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([0.0, 0.0])\n",
    "neuron(x)"
   ],
   "metadata": {
    "id": "i-BZHFqnXpLL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7105825d-66f2-48db-a250-8a3bfe6be45d",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.426951Z",
     "iopub.execute_input": "2022-12-08T15:49:29.427479Z",
     "iopub.status.idle": "2022-12-08T15:49:29.438498Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.427443Z",
     "shell.execute_reply": "2022-12-08T15:49:29.437413Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0, 0.0 ])\n",
    "neuron(x)"
   ],
   "metadata": {
    "outputId": "8181961c-7669-4a37-c4ce-1277622af170",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZuFtRlvyixQ",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.440045Z",
     "iopub.execute_input": "2022-12-08T15:49:29.440919Z",
     "iopub.status.idle": "2022-12-08T15:49:29.448663Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.440886Z",
     "shell.execute_reply": "2022-12-08T15:49:29.447274Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([0.0, 1.0 ])\n",
    "neuron(x)"
   ],
   "metadata": {
    "outputId": "26449834-8084-4c6a-a696-141449d0622f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyu88Kg0yixR",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.450607Z",
     "iopub.execute_input": "2022-12-08T15:49:29.451300Z",
     "iopub.status.idle": "2022-12-08T15:49:29.458887Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.451266Z",
     "shell.execute_reply": "2022-12-08T15:49:29.457763Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0, 1.0 ])\n",
    "neuron(x)"
   ],
   "metadata": {
    "outputId": "0100e5f4-c3a6-4188-9c5b-42cf823eb1e3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2OhYEC7yixS",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.460388Z",
     "iopub.execute_input": "2022-12-08T15:49:29.461120Z",
     "iopub.status.idle": "2022-12-08T15:49:29.468479Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.461085Z",
     "shell.execute_reply": "2022-12-08T15:49:29.467410Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Задача 5**. Cделать нейрон, соответствующий оператору XOR."
   ],
   "metadata": {
    "id": "1b95Z8u7Q3OL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
    "neuron.fc.bias.data = torch.tensor([0.0])"
   ],
   "metadata": {
    "id": "hWP7ee7tjCGv",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.470433Z",
     "iopub.execute_input": "2022-12-08T15:49:29.471205Z",
     "iopub.status.idle": "2022-12-08T15:49:29.476441Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.471169Z",
     "shell.execute_reply": "2022-12-08T15:49:29.475539Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([0.0, 0.0])\n",
    "neuron(x)"
   ],
   "metadata": {
    "id": "HgDrZ7PBjGwJ",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.477883Z",
     "iopub.execute_input": "2022-12-08T15:49:29.478636Z",
     "iopub.status.idle": "2022-12-08T15:49:29.486822Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.478602Z",
     "shell.execute_reply": "2022-12-08T15:49:29.486045Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.], grad_fn=<NotImplemented>)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Занятие 2.**"
   ],
   "metadata": {
    "id": "zjM7DFps2rBi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [Pytorch autograd](https://pytorch.org/docs/stable/autograd.html)"
   ],
   "metadata": {
    "id": "KlS1ciOPBg7g"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Tutorial](https://www.youtube.com/watch?v=MswxJw-8PvE)\n",
    "\n",
    "[Slides](https://app.diagrams.net/#G1bq3akhmA5DGRCiFYJfNPSn7il2wvCkEY)\n",
    "\n",
    "[Torch C++ Binary operations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp)\n",
    "\n",
    "[Torch C++ Activations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/Activation.cpp)"
   ],
   "metadata": {
    "id": "kP06X1SrzLlm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def show_tensor_params(*tensors):\n",
    "  for x in tensors:\n",
    "    print('---')\n",
    "    print(f\"data - {x.data}\")\n",
    "    print(f\"grad - {x.grad}\")\n",
    "    print(f\"grad_fn - {x.grad_fn}\")\n",
    "    print(f\"req_grad - {x.requires_grad}\")\n",
    "    print(f\"is_leaf - {x.is_leaf}\")"
   ],
   "metadata": {
    "id": "ipOjjh8OCk4u",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.495889Z",
     "iopub.execute_input": "2022-12-08T15:49:29.496525Z",
     "iopub.status.idle": "2022-12-08T15:49:29.504268Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.496488Z",
     "shell.execute_reply": "2022-12-08T15:49:29.503280Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor(5.0)\n",
    "show_tensor_params(x)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXas0qEnybl9",
    "outputId": "5e4bcc93-2541-4f5d-adf6-578ad58e391e",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.505724Z",
     "iopub.execute_input": "2022-12-08T15:49:29.506493Z",
     "iopub.status.idle": "2022-12-08T15:49:29.515606Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.506459Z",
     "shell.execute_reply": "2022-12-08T15:49:29.514549Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - 5.0\n",
      "grad - None\n",
      "grad_fn - None\n",
      "req_grad - False\n",
      "is_leaf - True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "All Tensors that have **requires_grad** which is **False** will be leaf Tensors by convention.\n",
    "\n",
    "For Tensors that have **requires_grad** which is **True**, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so **grad_fn** is None.\n",
    "\n",
    "Only leaf Tensors will have their **grad** populated during a call to backward(). To get grad populated for non-leaf Tensors, you can use retain_grad().[[Link]](https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf)"
   ],
   "metadata": {
    "id": "NuymHxbjzDfP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Slide A4\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0)\n",
    "c = a*b\n",
    "\n",
    "c.backward()\n",
    "# (2 * c).backward()"
   ],
   "metadata": {
    "id": "O5NE4zRPyqTT",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.517261Z",
     "iopub.execute_input": "2022-12-08T15:49:29.518008Z",
     "iopub.status.idle": "2022-12-08T15:49:29.527555Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.517973Z",
     "shell.execute_reply": "2022-12-08T15:49:29.526844Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_tensor_params(a, b, c)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-TbdvmH-oaM",
    "outputId": "4a390c62-06af-4ee1-f086-09ca09c2d70b",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.529221Z",
     "iopub.execute_input": "2022-12-08T15:49:29.530134Z",
     "iopub.status.idle": "2022-12-08T15:49:29.536977Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.530095Z",
     "shell.execute_reply": "2022-12-08T15:49:29.535900Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - 2.0\n",
      "grad - 3.0\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n",
      "---\n",
      "data - 3.0\n",
      "grad - None\n",
      "grad_fn - None\n",
      "req_grad - False\n",
      "is_leaf - True\n",
      "---\n",
      "data - 6.0\n",
      "grad - None\n",
      "grad_fn - <MulBackward0 object at 0x7f6ae833dea0>\n",
      "req_grad - True\n",
      "is_leaf - False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31044/138193020.py:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/build/aten/src/ATen/core/TensorBody.h:480.)\n",
      "  print(f\"grad - {x.grad}\")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Slide Simple5"
   ],
   "metadata": {
    "id": "NqUcFO2rCXni",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.538674Z",
     "iopub.execute_input": "2022-12-08T15:49:29.539501Z",
     "iopub.status.idle": "2022-12-08T15:49:29.543874Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.539466Z",
     "shell.execute_reply": "2022-12-08T15:49:29.542856Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = a*b\n",
    "d = torch.tensor(4.0, requires_grad=True)\n",
    "e = c*d\n",
    "\n",
    "c.retain_grad()\n",
    "e.retain_grad()\n",
    "e.backward()"
   ],
   "metadata": {
    "id": "gYTsuKc3Fn8r",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.545416Z",
     "iopub.execute_input": "2022-12-08T15:49:29.546173Z",
     "iopub.status.idle": "2022-12-08T15:49:29.554536Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.546139Z",
     "shell.execute_reply": "2022-12-08T15:49:29.553838Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_tensor_params(a, b, c, d, e)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egTBJvIBF5EO",
    "outputId": "9efd5963-c845-441f-98bd-e2bfccf5f864",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:49:29.556103Z",
     "iopub.execute_input": "2022-12-08T15:49:29.556770Z",
     "iopub.status.idle": "2022-12-08T15:49:29.563895Z",
     "shell.execute_reply.started": "2022-12-08T15:49:29.556735Z",
     "shell.execute_reply": "2022-12-08T15:49:29.563041Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - 2.0\n",
      "grad - 12.0\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n",
      "---\n",
      "data - 3.0\n",
      "grad - 8.0\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n",
      "---\n",
      "data - 6.0\n",
      "grad - 4.0\n",
      "grad_fn - <MulBackward0 object at 0x7f6ae833ee00>\n",
      "req_grad - True\n",
      "is_leaf - False\n",
      "---\n",
      "data - 4.0\n",
      "grad - 6.0\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n",
      "---\n",
      "data - 24.0\n",
      "grad - 1.0\n",
      "grad_fn - <MulBackward0 object at 0x7f6ae833ee00>\n",
      "req_grad - True\n",
      "is_leaf - False\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#In place 1\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = a*b\n",
    "d = torch.tensor(4.0, requires_grad=True)\n",
    "e = c*d\n",
    "c += 1\n",
    "\n",
    "try:\n",
    "    e.backward()\n",
    "except RuntimeError as re:\n",
    "    print(re)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "W5Cs2_REGgOS",
    "outputId": "052158cf-8dba-440f-9e54-e42d5f8cc019",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:20.530529Z",
     "iopub.execute_input": "2022-12-08T15:50:20.530900Z",
     "iopub.status.idle": "2022-12-08T15:50:20.544606Z",
     "shell.execute_reply.started": "2022-12-08T15:50:20.530870Z",
     "shell.execute_reply": "2022-12-08T15:50:20.543254Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(c._version)\n",
    "print(d._version)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WeqfWzYGhKG",
    "outputId": "fff4c374-1755-4cd9-89c1-490bc49a9be2",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:24.694920Z",
     "iopub.execute_input": "2022-12-08T15:50:24.695616Z",
     "iopub.status.idle": "2022-12-08T15:50:24.701439Z",
     "shell.execute_reply.started": "2022-12-08T15:50:24.695580Z",
     "shell.execute_reply": "2022-12-08T15:50:24.700279Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#In place 2\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = a*b\n",
    "d = torch.tensor(4.0, requires_grad=True)\n",
    "e = c+d\n",
    "c += 1\n",
    "\n",
    "e.backward()"
   ],
   "metadata": {
    "id": "iLZ3Z4qIH4J4",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:26.673055Z",
     "iopub.execute_input": "2022-12-08T15:50:26.673735Z",
     "iopub.status.idle": "2022-12-08T15:50:26.681072Z",
     "shell.execute_reply.started": "2022-12-08T15:50:26.673699Z",
     "shell.execute_reply": "2022-12-08T15:50:26.680149Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(c._version)\n",
    "print(d._version)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ySSjlRUIH0e",
    "outputId": "93759314-cebe-41d2-882c-b59ad2043f2f",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:27.725391Z",
     "iopub.execute_input": "2022-12-08T15:50:27.725760Z",
     "iopub.status.idle": "2022-12-08T15:50:27.731092Z",
     "shell.execute_reply.started": "2022-12-08T15:50:27.725728Z",
     "shell.execute_reply": "2022-12-08T15:50:27.730091Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#In place 3\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = a*b\n",
    "d = torch.tensor(4.0, requires_grad=True)\n",
    "e = c+d\n",
    "c = c + 1\n",
    "\n",
    "e.backward()"
   ],
   "metadata": {
    "id": "KUD8tZEh5v1V",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:28.763750Z",
     "iopub.execute_input": "2022-12-08T15:50:28.764294Z",
     "iopub.status.idle": "2022-12-08T15:50:28.772128Z",
     "shell.execute_reply.started": "2022-12-08T15:50:28.764258Z",
     "shell.execute_reply": "2022-12-08T15:50:28.770121Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(c._version)\n",
    "print(d._version)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f64d6d43-160e-45c5-e256-457b11220314",
    "id": "3nSzWKz85v1Y",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:30.091499Z",
     "iopub.execute_input": "2022-12-08T15:50:30.091845Z",
     "iopub.status.idle": "2022-12-08T15:50:30.097669Z",
     "shell.execute_reply.started": "2022-12-08T15:50:30.091814Z",
     "shell.execute_reply": "2022-12-08T15:50:30.096669Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# отвязка от графа\n",
    "k = e.detach()"
   ],
   "metadata": {
    "id": "4jbSqPGkILEw",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:30.845864Z",
     "iopub.execute_input": "2022-12-08T15:50:30.846465Z",
     "iopub.status.idle": "2022-12-08T15:50:30.851061Z",
     "shell.execute_reply.started": "2022-12-08T15:50:30.846425Z",
     "shell.execute_reply": "2022-12-08T15:50:30.849845Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "k.storage == e.storage"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLKUQ08AJhZT",
    "outputId": "b2465faa-85e9-4e53-fa3f-80be11974202",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:31.562039Z",
     "iopub.execute_input": "2022-12-08T15:50:31.563222Z",
     "iopub.status.idle": "2022-12-08T15:50:31.571748Z",
     "shell.execute_reply.started": "2022-12-08T15:50:31.563186Z",
     "shell.execute_reply": "2022-12-08T15:50:31.570648Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "show_tensor_params(e, k)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eqo-PW2kJkaG",
    "outputId": "289035b8-cfd5-4b70-b47f-b1dc5e5c184c",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:32.654849Z",
     "iopub.execute_input": "2022-12-08T15:50:32.655408Z",
     "iopub.status.idle": "2022-12-08T15:50:32.667588Z",
     "shell.execute_reply.started": "2022-12-08T15:50:32.655355Z",
     "shell.execute_reply": "2022-12-08T15:50:32.666323Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - 10.0\n",
      "grad - None\n",
      "grad_fn - <AddBackward0 object at 0x7f6ae833ebc0>\n",
      "req_grad - True\n",
      "is_leaf - False\n",
      "---\n",
      "data - 10.0\n",
      "grad - None\n",
      "grad_fn - None\n",
      "req_grad - False\n",
      "is_leaf - True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31044/138193020.py:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/build/aten/src/ATen/core/TensorBody.h:480.)\n",
      "  print(f\"grad - {x.grad}\")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Создание собственной библиотеки автоматического дифференцирования"
   ],
   "metadata": {
    "id": "B8urvcsAKi62"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "id": "txwYkEHMftme",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:36.532897Z",
     "iopub.execute_input": "2022-12-08T15:50:36.533595Z",
     "iopub.status.idle": "2022-12-08T15:50:36.540044Z",
     "shell.execute_reply.started": "2022-12-08T15:50:36.533555Z",
     "shell.execute_reply": "2022-12-08T15:50:36.538978Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 17\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "\n",
    "def set_random_seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "    seed_everything(s, workers=True)\n",
    "\n",
    "\n",
    "SEED = 17\n",
    "set_random_seed(SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Простой пример"
   ],
   "metadata": {
    "id": "urGQXw9GgdQt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def f(x):\n",
    "  return 3*x**2 - 4*x + 5"
   ],
   "metadata": {
    "id": "bPNsEPbZfwXm",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:38.736785Z",
     "iopub.execute_input": "2022-12-08T15:50:38.737163Z",
     "iopub.status.idle": "2022-12-08T15:50:38.742376Z",
     "shell.execute_reply.started": "2022-12-08T15:50:38.737132Z",
     "shell.execute_reply": "2022-12-08T15:50:38.740877Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "f(3.0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKMjYubGfzo5",
    "outputId": "e4b624fd-bf9e-40d5-e390-d16bdf2ecaee",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:41.065446Z",
     "iopub.execute_input": "2022-12-08T15:50:41.065805Z",
     "iopub.status.idle": "2022-12-08T15:50:41.073171Z",
     "shell.execute_reply.started": "2022-12-08T15:50:41.065773Z",
     "shell.execute_reply": "2022-12-08T15:50:41.071940Z"
    },
    "trusted": true
   },
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "20.0"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "xs = np.arange(-5, 5, 0.25)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys);"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "2Mufja5Mf2dD",
    "outputId": "882942ce-e100-4e94-ab16-66df4a91bcd9",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:42.225113Z",
     "iopub.execute_input": "2022-12-08T15:50:42.225897Z",
     "iopub.status.idle": "2022-12-08T15:50:42.408917Z",
     "shell.execute_reply.started": "2022-12-08T15:50:42.225857Z",
     "shell.execute_reply": "2022-12-08T15:50:42.407941Z"
    },
    "trusted": true
   },
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "h = 0.000001\n",
    "x = 2\n",
    "(f(x + h) - f(x))/h"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzRAdjhFgGo8",
    "outputId": "80f5b90a-0446-4b37-b728-c6a0339c657f",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:44.037302Z",
     "iopub.execute_input": "2022-12-08T15:50:44.037665Z",
     "iopub.status.idle": "2022-12-08T15:50:44.044006Z",
     "shell.execute_reply.started": "2022-12-08T15:50:44.037633Z",
     "shell.execute_reply": "2022-12-08T15:50:44.043044Z"
    },
    "trusted": true
   },
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "8.000003001384925"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Более сложный пример"
   ],
   "metadata": {
    "id": "dOszwXaTgkd4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "a = 2.0\n",
    "b = -3.0\n",
    "c = 10.0\n",
    "d = a*b + c\n",
    "print(d)"
   ],
   "metadata": {
    "id": "BOzPl8NWghve",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aa8691ab-c4d2-4b94-d016-145849dd8d30",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:45.134053Z",
     "iopub.execute_input": "2022-12-08T15:50:45.135100Z",
     "iopub.status.idle": "2022-12-08T15:50:45.141375Z",
     "shell.execute_reply.started": "2022-12-08T15:50:45.135053Z",
     "shell.execute_reply": "2022-12-08T15:50:45.140087Z"
    },
    "trusted": true
   },
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "h = 0.0001\n",
    "\n",
    "# inputs\n",
    "a = 2.0\n",
    "b = -3.0\n",
    "c = 10.0\n",
    "\n",
    "d1 = a*b + c\n",
    "c += h\n",
    "d2 = a*b + c\n",
    "\n",
    "print('d1', d1)\n",
    "print('d2', d2)\n",
    "print('slope', (d2 - d1)/h)\n",
    "\n",
    "d1 = a*b + c\n",
    "a += h\n",
    "d2 = a*b + c\n",
    "\n",
    "print('d1', d1)\n",
    "print('d2', d2)\n",
    "print('slope', (d2 - d1)/h)\n",
    "\n",
    "d1 = a*b + c\n",
    "b += h\n",
    "d2 = a*b + c\n",
    "\n",
    "print('d1', d1)\n",
    "print('d2', d2)\n",
    "print('slope', (d2 - d1)/h)"
   ],
   "metadata": {
    "id": "P9Xx4_omgrkm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fca0e3f8-d66c-45f3-b9f0-7e4464d36c62",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:45.695698Z",
     "iopub.execute_input": "2022-12-08T15:50:45.696353Z",
     "iopub.status.idle": "2022-12-08T15:50:45.705143Z",
     "shell.execute_reply.started": "2022-12-08T15:50:45.696312Z",
     "shell.execute_reply": "2022-12-08T15:50:45.704079Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 4.0\n",
      "d2 4.0001\n",
      "slope 0.9999999999976694\n",
      "d1 4.0001\n",
      "d2 3.9997999999999987\n",
      "slope -3.000000000010772\n",
      "d1 3.9997999999999987\n",
      "d2 4.00000001\n",
      "slope 2.0001000000124947\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "wle8vv7_grKJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://pytorch.org/tutorials/beginner/examples_autograd/polynomial_custom_function.html"
   ],
   "metadata": {
    "id": "dlDJrMMsOgNh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.autograd import Function"
   ],
   "metadata": {
    "id": "sPyPkdq5RH94",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:50:48.109427Z",
     "iopub.execute_input": "2022-12-08T15:50:48.109885Z",
     "iopub.status.idle": "2022-12-08T15:50:48.116809Z",
     "shell.execute_reply.started": "2022-12-08T15:50:48.109838Z",
     "shell.execute_reply": "2022-12-08T15:50:48.115855Z"
    },
    "trusted": true
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Exp(Function):\n",
    "  \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "  @staticmethod\n",
    "  def forward(ctx, i):\n",
    "    \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "    \"\"\"\n",
    "    result = i.exp()\n",
    "    ctx.save_for_backward(result)\n",
    "    return result\n",
    "\n",
    "  @staticmethod\n",
    "  def backward(ctx, grad_output):\n",
    "    \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "    \"\"\"\n",
    "    print(ctx.saved_tensors)\n",
    "    result, = ctx.saved_tensors\n",
    "    return grad_output * result"
   ],
   "metadata": {
    "id": "F5-hnsEiPIz9",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:53:39.138335Z",
     "iopub.execute_input": "2022-12-08T15:53:39.138842Z",
     "iopub.status.idle": "2022-12-08T15:53:39.148477Z",
     "shell.execute_reply.started": "2022-12-08T15:53:39.138792Z",
     "shell.execute_reply": "2022-12-08T15:53:39.147328Z"
    },
    "trusted": true
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Use it by calling the apply method\n",
    "input = torch.tensor(2.0, requires_grad=True)\n",
    "output = Exp.apply(input)\n",
    "output"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elaOA8bdRiMc",
    "outputId": "be8842b1-682f-4249-dd66-49961d4a93a8",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:53:41.187644Z",
     "iopub.execute_input": "2022-12-08T15:53:41.188008Z",
     "iopub.status.idle": "2022-12-08T15:53:41.200265Z",
     "shell.execute_reply.started": "2022-12-08T15:53:41.187974Z",
     "shell.execute_reply": "2022-12-08T15:53:41.199234Z"
    },
    "trusted": true
   },
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(7.3891, grad_fn=<ExpBackward>)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "math.exp(2.0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlcZLt-RSGgG",
    "outputId": "2ba81786-2183-4de7-ae7d-bd92ee5234f1",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:53:45.630088Z",
     "iopub.execute_input": "2022-12-08T15:53:45.630446Z",
     "iopub.status.idle": "2022-12-08T15:53:45.637576Z",
     "shell.execute_reply.started": "2022-12-08T15:53:45.630414Z",
     "shell.execute_reply": "2022-12-08T15:53:45.636355Z"
    },
    "trusted": true
   },
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "7.38905609893065"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "output.backward()\n",
    "show_tensor_params(output)\n",
    "show_tensor_params(input)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Om6dn414SQeA",
    "outputId": "2021d2ec-917e-4da2-8ce7-0fca5b549dfc",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:53:48.671570Z",
     "iopub.execute_input": "2022-12-08T15:53:48.672152Z",
     "iopub.status.idle": "2022-12-08T15:53:48.680246Z",
     "shell.execute_reply.started": "2022-12-08T15:53:48.672107Z",
     "shell.execute_reply": "2022-12-08T15:53:48.678918Z"
    },
    "trusted": true
   },
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(7.3891, grad_fn=<ExpBackward>),)\n",
      "---\n",
      "data - 7.389056205749512\n",
      "grad - None\n",
      "grad_fn - <torch.autograd.function.ExpBackward object at 0x7f6ac8da6e30>\n",
      "req_grad - True\n",
      "is_leaf - False\n",
      "---\n",
      "data - 2.0\n",
      "grad - 7.389056205749512\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31044/138193020.py:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/build/aten/src/ATen/core/TensorBody.h:480.)\n",
      "  print(f\"grad - {x.grad}\")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание**: реализуйте backward для Polynomial 0.5 * (5 * input ** 3 - 3 * input)"
   ],
   "metadata": {
    "id": "d_14IqfeSnLM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Polynomial(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        result = 0.5 * (5 * input ** 3 - 3 * input)\n",
    "        grad = 7.5 * input ** 2 - 1.5\n",
    "        ctx.save_for_backward(grad)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        print(ctx.saved_tensors)\n",
    "        grad, = ctx.saved_tensors\n",
    "        return grad_output * grad\n",
    "        "
   ],
   "metadata": {
    "id": "i5cNegVYOd8u",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:57:46.093868Z",
     "iopub.execute_input": "2022-12-08T15:57:46.094966Z",
     "iopub.status.idle": "2022-12-08T15:57:46.102129Z",
     "shell.execute_reply.started": "2022-12-08T15:57:46.094912Z",
     "shell.execute_reply": "2022-12-08T15:57:46.101071Z"
    },
    "trusted": true
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input = torch.tensor(2.0, requires_grad=True)\n",
    "Polynomial.apply(input)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZERCX7g_1WS",
    "outputId": "5f2b0174-3a37-4c7d-a7b5-25bd97d1c0c5",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:57:48.369655Z",
     "iopub.execute_input": "2022-12-08T15:57:48.370031Z",
     "iopub.status.idle": "2022-12-08T15:57:48.379752Z",
     "shell.execute_reply.started": "2022-12-08T15:57:48.369984Z",
     "shell.execute_reply": "2022-12-08T15:57:48.378767Z"
    },
    "trusted": true
   },
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(17., grad_fn=<PolynomialBackward>)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "p = Polynomial.apply(input)\n",
    "p.backward()\n",
    "show_tensor_params(input)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5Nw3ByaAfsS",
    "outputId": "1f9272dc-ac07-40f6-9847-06792331a342",
    "execution": {
     "iopub.status.busy": "2022-12-08T15:57:49.202272Z",
     "iopub.execute_input": "2022-12-08T15:57:49.202626Z",
     "iopub.status.idle": "2022-12-08T15:57:49.209783Z",
     "shell.execute_reply.started": "2022-12-08T15:57:49.202594Z",
     "shell.execute_reply": "2022-12-08T15:57:49.208601Z"
    },
    "trusted": true
   },
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(28.5000),)\n",
      "---\n",
      "data - 2.0\n",
      "grad - 28.5\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_tensor = torch.tensor(2.0, requires_grad=True)\n",
    "e = Exp.apply(input_tensor)\n",
    "p = Polynomial.apply(e)\n",
    "print(p)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-08T16:01:52.021807Z",
     "iopub.execute_input": "2022-12-08T16:01:52.022226Z",
     "iopub.status.idle": "2022-12-08T16:01:52.029856Z",
     "shell.execute_reply.started": "2022-12-08T16:01:52.022195Z",
     "shell.execute_reply": "2022-12-08T16:01:52.028824Z"
    },
    "trusted": true
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(997.4885, grad_fn=<PolynomialBackward>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "p.backward()\n",
    "show_tensor_params(input_tensor)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-08T16:01:52.605669Z",
     "iopub.execute_input": "2022-12-08T16:01:52.606010Z",
     "iopub.status.idle": "2022-12-08T16:01:52.613283Z",
     "shell.execute_reply.started": "2022-12-08T16:01:52.605972Z",
     "shell.execute_reply": "2022-12-08T16:01:52.612238Z"
    },
    "trusted": true
   },
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(407.9861),)\n",
      "(tensor(7.3891, grad_fn=<ExpBackward>),)\n",
      "---\n",
      "data - 2.0\n",
      "grad - 3014.632568359375\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_tensor = torch.tensor(2.0, requires_grad=True)\n",
    "e = Exp.apply(input_tensor)\n",
    "e = Exp.apply(e)\n",
    "print(e)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-08T16:03:13.301352Z",
     "iopub.execute_input": "2022-12-08T16:03:13.301708Z",
     "iopub.status.idle": "2022-12-08T16:03:13.309658Z",
     "shell.execute_reply.started": "2022-12-08T16:03:13.301678Z",
     "shell.execute_reply": "2022-12-08T16:03:13.308711Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1618.1781, grad_fn=<ExpBackward>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "e.backward()\n",
    "show_tensor_params(input_tensor)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-08T16:03:15.063827Z",
     "iopub.execute_input": "2022-12-08T16:03:15.064494Z",
     "iopub.status.idle": "2022-12-08T16:03:15.071730Z",
     "shell.execute_reply.started": "2022-12-08T16:03:15.064456Z",
     "shell.execute_reply": "2022-12-08T16:03:15.070415Z"
    },
    "trusted": true
   },
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1618.1781, grad_fn=<ExpBackward>),)\n",
      "(tensor(7.3891, grad_fn=<ExpBackward>),)\n",
      "---\n",
      "data - 2.0\n",
      "grad - 11956.80859375\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_tensor = torch.tensor(2.0, requires_grad=True)\n",
    "exp = Exp()\n",
    "e = exp.apply(input_tensor)\n",
    "e = exp.apply(e)\n",
    "print(e)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-08T16:06:33.887380Z",
     "iopub.execute_input": "2022-12-08T16:06:33.887742Z",
     "iopub.status.idle": "2022-12-08T16:06:33.895569Z",
     "shell.execute_reply.started": "2022-12-08T16:06:33.887711Z",
     "shell.execute_reply": "2022-12-08T16:06:33.894558Z"
    },
    "trusted": true
   },
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1618.1781, grad_fn=<ExpBackward>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "e.backward()\n",
    "show_tensor_params(input_tensor)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-08T16:06:40.462821Z",
     "iopub.execute_input": "2022-12-08T16:06:40.463812Z",
     "iopub.status.idle": "2022-12-08T16:06:40.471069Z",
     "shell.execute_reply.started": "2022-12-08T16:06:40.463778Z",
     "shell.execute_reply": "2022-12-08T16:06:40.469961Z"
    },
    "trusted": true
   },
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1618.1781, grad_fn=<ExpBackward>),)\n",
      "(tensor(7.3891, grad_fn=<ExpBackward>),)\n",
      "---\n",
      "data - 2.0\n",
      "grad - 11956.80859375\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Практическое задание: написать собственный движок автоматического дифференцирования, а именно: реализовать"
   ],
   "metadata": {
    "id": "fA2PNhudUNij"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Value:\n",
    "    \"\"\" stores a single scalar value and its gradient \"\"\"\n",
    "\n",
    "    def __init__(self, data, _children=(), _op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0\n",
    "        # internal variables used for autograd graph construction\n",
    "        self._backward = lambda prev_grad: None  # function\n",
    "        self._prev = set(_children)  # set of Value objects\n",
    "        self._op = _op  # the op that produced this node, string ('+', '-', ....)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data)\n",
    "\n",
    "        def _backward(pred_grad):\n",
    "            self.grad += 1 * pred_grad\n",
    "            other.grad += 1 * pred_grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        out._prev = {self, other}\n",
    "        out._op = '+'\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(other.data * self.data)\n",
    "\n",
    "        def _backward(pred_grad):\n",
    "            self.grad += other.data * pred_grad\n",
    "            other.grad += self.data * pred_grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        out._prev = {self, other}\n",
    "        out._op = '*'\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "        out = Value(self.data ** other)\n",
    "\n",
    "        def _backward(pred_grad):\n",
    "            self.grad += other * self.data ** (other - 1) * pred_grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        out._prev = {self}\n",
    "        out._op = '^'\n",
    "\n",
    "        return out\n",
    "\n",
    "    def relu(self):\n",
    "        out = Value(self.data if self.data > 0 else 0)\n",
    "\n",
    "        def _backward(pred_grad):\n",
    "            self.grad += (1 if self.data > 0 else 0) * pred_grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        out._prev = {self}\n",
    "        out._op = 'ReLU'\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        # topological order all of the children in the graph\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "\n",
    "        build_topo(self)\n",
    "\n",
    "        # go one variable at a time and apply the chain rule to get its gradient\n",
    "        self.grad = 1\n",
    "        for v in reversed(topo):\n",
    "            v._backward(v.grad)\n",
    "\n",
    "    def __neg__(self):  # -self\n",
    "        return self * -1\n",
    "\n",
    "    def __radd__(self, other):  # other + self\n",
    "        return self + other\n",
    "\n",
    "    def __sub__(self, other):  # self - other\n",
    "        return self + (-other)\n",
    "\n",
    "    def __rsub__(self, other):  # other - self\n",
    "        return other + (-self)\n",
    "\n",
    "    def __rmul__(self, other):  # other * self\n",
    "        return self * other\n",
    "\n",
    "    def __truediv__(self, other):  # self / other\n",
    "        return self * other ** -1\n",
    "\n",
    "    def __rtruediv__(self, other):  # other / self\n",
    "        return other * self ** -1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data}, grad={self.grad})\"\n",
    "\n"
   ],
   "metadata": {
    "id": "chDdD9oSUlUJ",
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2022-12-08T16:36:43.175567Z",
     "iopub.execute_input": "2022-12-08T16:36:43.175926Z",
     "iopub.status.idle": "2022-12-08T16:36:43.193195Z",
     "shell.execute_reply.started": "2022-12-08T16:36:43.175894Z",
     "shell.execute_reply": "2022-12-08T16:36:43.192251Z"
    },
    "trusted": true
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test_sanity_check():\n",
    "\n",
    "    x = Value(-4.0)\n",
    "    z = 2 * x + 2 + x\n",
    "  \n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    xmg, ymg = x, y\n",
    "\n",
    "    x = torch.Tensor([-4.0]).double()\n",
    "    x.requires_grad = True\n",
    "    z = 2 * x + 2 + x\n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    xpt, ypt = x, y\n",
    "\n",
    "    \n",
    "    # forward pass went well\n",
    "    assert ymg.data == ypt.data.item()\n",
    "    # backward pass went well\n",
    "    print(xmg, xpt, xpt.grad)\n",
    "    assert xmg.grad == xpt.grad.item()\n",
    "\n",
    "\n",
    "def test_more_ops():\n",
    "\n",
    "    a = Value(-4.0)\n",
    "    b = Value(2.0)\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c += c + 1\n",
    "    c += 1 + c + (-a)\n",
    "    d += d * 2 + (b + a).relu()\n",
    "    d += 3 * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g += 10.0 / f\n",
    "    g.backward()\n",
    "    amg, bmg, gmg = a, b, g\n",
    "\n",
    "    a = torch.Tensor([-4.0]).double()\n",
    "    b = torch.Tensor([2.0]).double()\n",
    "    a.requires_grad = True\n",
    "    b.requires_grad = True\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c = c + c + 1\n",
    "    c = c + 1 + c + (-a)\n",
    "    d = d + d * 2 + (b + a).relu()\n",
    "    d = d + 3 * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g = g + 10.0 / f\n",
    "    g.backward()\n",
    "    apt, bpt, gpt = a, b, g\n",
    "\n",
    "    tol = 1e-6\n",
    "    # forward pass went well\n",
    "    assert abs(gmg.data - gpt.data.item()) < tol\n",
    "    # backward pass went well\n",
    "    assert abs(amg.grad - apt.grad.item()) < tol\n",
    "    assert abs(bmg.grad - bpt.grad.item()) < tol"
   ],
   "metadata": {
    "id": "vY7OzWjuUiaa",
    "execution": {
     "iopub.status.busy": "2022-12-08T16:36:31.362458Z",
     "iopub.execute_input": "2022-12-08T16:36:31.362802Z",
     "iopub.status.idle": "2022-12-08T16:36:31.377284Z",
     "shell.execute_reply.started": "2022-12-08T16:36:31.362773Z",
     "shell.execute_reply": "2022-12-08T16:36:31.376196Z"
    },
    "trusted": true
   },
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = Value(-4.0)\n",
    "b = Value(2.0)\n",
    "d = Value(3.0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LgTiYeZ-WGk",
    "outputId": "a334fd44-c71e-4f4e-ce44-301e90d1d03e",
    "execution": {
     "iopub.status.busy": "2022-12-08T16:36:33.095130Z",
     "iopub.execute_input": "2022-12-08T16:36:33.095545Z",
     "iopub.status.idle": "2022-12-08T16:36:33.103936Z",
     "shell.execute_reply.started": "2022-12-08T16:36:33.095511Z",
     "shell.execute_reply": "2022-12-08T16:36:33.102798Z"
    },
    "trusted": true
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "c = a + b\n",
    "e = c * d\n",
    "e.backward()"
   ],
   "metadata": {
    "id": "Y0svSAs2h0Ap",
    "execution": {
     "iopub.status.busy": "2022-12-08T16:36:33.716770Z",
     "iopub.execute_input": "2022-12-08T16:36:33.717312Z",
     "iopub.status.idle": "2022-12-08T16:36:33.722739Z",
     "shell.execute_reply.started": "2022-12-08T16:36:33.717270Z",
     "shell.execute_reply": "2022-12-08T16:36:33.721707Z"
    },
    "trusted": true
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_sanity_check()"
   ],
   "metadata": {
    "id": "w9n8DN6RYkrx",
    "execution": {
     "iopub.status.busy": "2022-12-08T16:36:34.866380Z",
     "iopub.execute_input": "2022-12-08T16:36:34.866751Z",
     "iopub.status.idle": "2022-12-08T16:36:34.890964Z",
     "shell.execute_reply.started": "2022-12-08T16:36:34.866719Z",
     "shell.execute_reply": "2022-12-08T16:36:34.889690Z"
    },
    "trusted": true
   },
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=-4.0, grad=46.0) tensor([-4.], dtype=torch.float64, requires_grad=True) tensor([46.], dtype=torch.float64)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_more_ops()"
   ],
   "metadata": {
    "id": "1T198QDQYh_q"
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение на основе собственной бибилотеки"
   ],
   "metadata": {
    "id": "o-KbDOhMYHZ1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Многослойный перцептрон на основе класса Value"
   ],
   "metadata": {
    "id": "uVK1JLXom0Ze"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Module:\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.grad = 0\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class Neuron(Module):\n",
    "\n",
    "    def __init__(self, nin, nonlin=True):\n",
    "        self.w = [Value(np.random.rand()) for i in range(nin)]\n",
    "        self.b = Value(np.random.rand())\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "    def __call__(self, x):\n",
    "        batch_s = len(x)\n",
    "        nin = len(x[0])\n",
    "        res = [self.b for i in range(batch_s)]\n",
    "        for i in range(batch_s):\n",
    "            for j in range(nin):\n",
    "                res[i] += self.w[j] * x[i][j]\n",
    "        return [r.relu() for r in res] if self.nonlin else res\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for weight in self.w:\n",
    "            weight.grad = 0\n",
    "        self.b.grad = 0\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"\n",
    "\n",
    "\n",
    "class Layer(Module):\n",
    "\n",
    "    def __init__(self, nin, nout, **kwargs):\n",
    "        self.neurons = [Neuron(nin, kwargs['nonlin']) for i in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = [[] for i in range(len(x))]\n",
    "        for n in self.neurons:\n",
    "            n_out = n(x)\n",
    "            for i in range(len(x)):\n",
    "                out[i].append(n_out[i])\n",
    "        return out[0] if len(out) == 1 else out\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for n in self.neurons:\n",
    "            n.zero_grad()\n",
    "\n",
    "    def parameters(self):\n",
    "        l_params = []\n",
    "        for n in self.neurons:\n",
    "            l_params.extend(n.parameters())\n",
    "        return l_params\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n",
    "\n",
    "\n",
    "class MLP(Module):\n",
    "\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1], nonlin=(i != len(nouts) - 1)) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for l in self.layers:\n",
    "            l.zero_grad()\n",
    "\n",
    "    def parameters(self):\n",
    "        nn_params = []\n",
    "        for l in self.layers:\n",
    "            nn_params.extend(l.parameters())\n",
    "        return nn_params\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr = '\\n'.join(str(layer) for layer in self.layers)\n",
    "        return f\"MLP of [{repr}]\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучение многослойного перцептрона"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сам перцептрон"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)]\n",
      "Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)]\n",
      "Layer of [LinearNeuron(4)]]\n",
      "number of parameters 41\n"
     ]
    }
   ],
   "source": [
    "nn = MLP(3, [4, 4, 1])  # 3 входящих признака, 1-й слой из 4-х нейронов, 2-й слой из 4-х нейронов, 3-й слой из одного нейрона\n",
    "# 1-й слой: 3 входящих признака, 4 исходящих признака\n",
    "# 2-й слой: 4 входящих признака, 4 исходящих признака\n",
    "# 3-й слой: 4 входящих признака, 1 исходящий признак\n",
    "\n",
    "# print(model)  # model -> nn ?\n",
    "print(nn)\n",
    "# print(\"number of parameters\", len(model.parameters()))  # model -> nn ?\n",
    "print(\"number of parameters\", len(nn.parameters()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Набор данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "set_random_seed(SEED)\n",
    "learning_rate = 0.01\n",
    "\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "\n",
    "for k in range(150):\n",
    "    nn.zero_grad()\n",
    "\n",
    "    # forward\n",
    "    pred = nn(xs)\n",
    "\n",
    "    # calculate loss (mean square error)\n",
    "    total_loss = Value(0)\n",
    "    for i in range(len(ys)):\n",
    "        total_loss += (pred[i][0] - ys[i]) ** 2\n",
    "    total_loss /= len(xs)\n",
    "\n",
    "    # backward (zero_grad + backward)\n",
    "    total_loss.backward()\n",
    "    loss_hist.append(total_loss.data)\n",
    "\n",
    "    mean_y = 0\n",
    "    for y in ys:\n",
    "        mean_y += y\n",
    "    mean_y /= len(ys)\n",
    "    var_y = 0\n",
    "    for y in ys:\n",
    "        var_y += (y - mean_y) ** 2\n",
    "    var_y /= len(ys)\n",
    "    acc = 1 - total_loss.data / var_y\n",
    "    acc_hist.append(0 if acc < 0 else acc)\n",
    "\n",
    "    # update\n",
    "    # for layer_p in nn.parameters():\n",
    "    #     for neuron_p in layer_p:\n",
    "    #         for w in neuron_p[0]:\n",
    "    #             w.data -= w.grad * learning_rate\n",
    "    #         neuron_p[1].data -= neuron_p[1].grad\n",
    "    for p in nn.parameters():\n",
    "        p.data -= p.grad * learning_rate\n",
    "\n",
    "    if k % 1 == 0:\n",
    "        print(f\"step: {k}, loss: {round(total_loss.data, 6)}, accuracy R^2: {round(acc * 100, 2)}%\")\n",
    "\n",
    "print(pred, ys)"
   ],
   "metadata": {
    "id": "OuCTaTB8n5l0"
   },
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 66.386018, accuracy R^2: -6538.6%\n",
      "step: 1, loss: 1.064098, accuracy R^2: -6.41%\n",
      "step: 2, loss: 1.054274, accuracy R^2: -5.43%\n",
      "step: 3, loss: 1.044591, accuracy R^2: -4.46%\n",
      "step: 4, loss: 1.03503, accuracy R^2: -3.5%\n",
      "step: 5, loss: 1.025575, accuracy R^2: -2.56%\n",
      "step: 6, loss: 1.016213, accuracy R^2: -1.62%\n",
      "step: 7, loss: 1.006932, accuracy R^2: -0.69%\n",
      "step: 8, loss: 0.997723, accuracy R^2: 0.23%\n",
      "step: 9, loss: 0.988575, accuracy R^2: 1.14%\n",
      "step: 10, loss: 0.979479, accuracy R^2: 2.05%\n",
      "step: 11, loss: 0.970428, accuracy R^2: 2.96%\n",
      "step: 12, loss: 0.961412, accuracy R^2: 3.86%\n",
      "step: 13, loss: 0.952425, accuracy R^2: 4.76%\n",
      "step: 14, loss: 0.943459, accuracy R^2: 5.65%\n",
      "step: 15, loss: 0.934508, accuracy R^2: 6.55%\n",
      "step: 16, loss: 0.925564, accuracy R^2: 7.44%\n",
      "step: 17, loss: 0.91662, accuracy R^2: 8.34%\n",
      "step: 18, loss: 0.907671, accuracy R^2: 9.23%\n",
      "step: 19, loss: 0.89871, accuracy R^2: 10.13%\n",
      "step: 20, loss: 0.88973, accuracy R^2: 11.03%\n",
      "step: 21, loss: 0.880726, accuracy R^2: 11.93%\n",
      "step: 22, loss: 0.871692, accuracy R^2: 12.83%\n",
      "step: 23, loss: 0.862622, accuracy R^2: 13.74%\n",
      "step: 24, loss: 0.85351, accuracy R^2: 14.65%\n",
      "step: 25, loss: 0.84435, accuracy R^2: 15.56%\n",
      "step: 26, loss: 0.835137, accuracy R^2: 16.49%\n",
      "step: 27, loss: 0.825866, accuracy R^2: 17.41%\n",
      "step: 28, loss: 0.816531, accuracy R^2: 18.35%\n",
      "step: 29, loss: 0.807126, accuracy R^2: 19.29%\n",
      "step: 30, loss: 0.797647, accuracy R^2: 20.24%\n",
      "step: 31, loss: 0.788088, accuracy R^2: 21.19%\n",
      "step: 32, loss: 0.778444, accuracy R^2: 22.16%\n",
      "step: 33, loss: 0.76871, accuracy R^2: 23.13%\n",
      "step: 34, loss: 0.758882, accuracy R^2: 24.11%\n",
      "step: 35, loss: 0.748954, accuracy R^2: 25.1%\n",
      "step: 36, loss: 0.738922, accuracy R^2: 26.11%\n",
      "step: 37, loss: 0.728781, accuracy R^2: 27.12%\n",
      "step: 38, loss: 0.718528, accuracy R^2: 28.15%\n",
      "step: 39, loss: 0.708157, accuracy R^2: 29.18%\n",
      "step: 40, loss: 0.697665, accuracy R^2: 30.23%\n",
      "step: 41, loss: 0.687049, accuracy R^2: 31.3%\n",
      "step: 42, loss: 0.676305, accuracy R^2: 32.37%\n",
      "step: 43, loss: 0.665429, accuracy R^2: 33.46%\n",
      "step: 44, loss: 0.65442, accuracy R^2: 34.56%\n",
      "step: 45, loss: 0.643274, accuracy R^2: 35.67%\n",
      "step: 46, loss: 0.631989, accuracy R^2: 36.8%\n",
      "step: 47, loss: 0.620564, accuracy R^2: 37.94%\n",
      "step: 48, loss: 0.608998, accuracy R^2: 39.1%\n",
      "step: 49, loss: 0.597291, accuracy R^2: 40.27%\n",
      "step: 50, loss: 0.585442, accuracy R^2: 41.46%\n",
      "step: 51, loss: 0.573452, accuracy R^2: 42.65%\n",
      "step: 52, loss: 0.561322, accuracy R^2: 43.87%\n",
      "step: 53, loss: 0.549056, accuracy R^2: 45.09%\n",
      "step: 54, loss: 0.536655, accuracy R^2: 46.33%\n",
      "step: 55, loss: 0.524124, accuracy R^2: 47.59%\n",
      "step: 56, loss: 0.511468, accuracy R^2: 48.85%\n",
      "step: 57, loss: 0.498693, accuracy R^2: 50.13%\n",
      "step: 58, loss: 0.485806, accuracy R^2: 51.42%\n",
      "step: 59, loss: 0.472815, accuracy R^2: 52.72%\n",
      "step: 60, loss: 0.459728, accuracy R^2: 54.03%\n",
      "step: 61, loss: 0.446558, accuracy R^2: 55.34%\n",
      "step: 62, loss: 0.433315, accuracy R^2: 56.67%\n",
      "step: 63, loss: 0.420012, accuracy R^2: 58.0%\n",
      "step: 64, loss: 0.406663, accuracy R^2: 59.33%\n",
      "step: 65, loss: 0.393285, accuracy R^2: 60.67%\n",
      "step: 66, loss: 0.379893, accuracy R^2: 62.01%\n",
      "step: 67, loss: 0.366506, accuracy R^2: 63.35%\n",
      "step: 68, loss: 0.353142, accuracy R^2: 64.69%\n",
      "step: 69, loss: 0.340211, accuracy R^2: 65.98%\n",
      "step: 70, loss: 0.327583, accuracy R^2: 67.24%\n",
      "step: 71, loss: 0.315031, accuracy R^2: 68.5%\n",
      "step: 72, loss: 0.302548, accuracy R^2: 69.75%\n",
      "step: 73, loss: 0.290231, accuracy R^2: 70.98%\n",
      "step: 74, loss: 0.277977, accuracy R^2: 72.2%\n",
      "step: 75, loss: 0.265961, accuracy R^2: 73.4%\n",
      "step: 76, loss: 0.254024, accuracy R^2: 74.6%\n",
      "step: 77, loss: 0.242405, accuracy R^2: 75.76%\n",
      "step: 78, loss: 0.230879, accuracy R^2: 76.91%\n",
      "step: 79, loss: 0.219661, accuracy R^2: 78.03%\n",
      "step: 80, loss: 0.208615, accuracy R^2: 79.14%\n",
      "step: 81, loss: 0.197893, accuracy R^2: 80.21%\n",
      "step: 82, loss: 0.187418, accuracy R^2: 81.26%\n",
      "step: 83, loss: 0.177249, accuracy R^2: 82.28%\n",
      "step: 84, loss: 0.167413, accuracy R^2: 83.26%\n",
      "step: 85, loss: 0.157851, accuracy R^2: 84.21%\n",
      "step: 86, loss: 0.148698, accuracy R^2: 85.13%\n",
      "step: 87, loss: 0.139824, accuracy R^2: 86.02%\n",
      "step: 88, loss: 0.131319, accuracy R^2: 86.87%\n",
      "step: 89, loss: 0.123199, accuracy R^2: 87.68%\n",
      "step: 90, loss: 0.115393, accuracy R^2: 88.46%\n",
      "step: 91, loss: 0.107977, accuracy R^2: 89.2%\n",
      "step: 92, loss: 0.10093, accuracy R^2: 89.91%\n",
      "step: 93, loss: 0.094211, accuracy R^2: 90.58%\n",
      "step: 94, loss: 0.087866, accuracy R^2: 91.21%\n",
      "step: 95, loss: 0.081887, accuracy R^2: 91.81%\n",
      "step: 96, loss: 0.07622, accuracy R^2: 92.38%\n",
      "step: 97, loss: 0.070891, accuracy R^2: 92.91%\n",
      "step: 98, loss: 0.065922, accuracy R^2: 93.41%\n",
      "step: 99, loss: 0.061236, accuracy R^2: 93.88%\n",
      "step: 100, loss: 0.056852, accuracy R^2: 94.31%\n",
      "step: 101, loss: 0.052766, accuracy R^2: 94.72%\n",
      "step: 102, loss: 0.048976, accuracy R^2: 95.1%\n",
      "step: 103, loss: 0.045428, accuracy R^2: 95.46%\n",
      "step: 104, loss: 0.042133, accuracy R^2: 95.79%\n",
      "step: 105, loss: 0.039079, accuracy R^2: 96.09%\n",
      "step: 106, loss: 0.036269, accuracy R^2: 96.37%\n",
      "step: 107, loss: 0.033649, accuracy R^2: 96.64%\n",
      "step: 108, loss: 0.031229, accuracy R^2: 96.88%\n",
      "step: 109, loss: 0.028994, accuracy R^2: 97.1%\n",
      "step: 110, loss: 0.02694, accuracy R^2: 97.31%\n",
      "step: 111, loss: 0.025048, accuracy R^2: 97.5%\n",
      "step: 112, loss: 0.023297, accuracy R^2: 97.67%\n",
      "step: 113, loss: 0.021686, accuracy R^2: 97.83%\n",
      "step: 114, loss: 0.020202, accuracy R^2: 97.98%\n",
      "step: 115, loss: 0.018842, accuracy R^2: 98.12%\n",
      "step: 116, loss: 0.017591, accuracy R^2: 98.24%\n",
      "step: 117, loss: 0.016435, accuracy R^2: 98.36%\n",
      "step: 118, loss: 0.015371, accuracy R^2: 98.46%\n",
      "step: 119, loss: 0.014393, accuracy R^2: 98.56%\n",
      "step: 120, loss: 0.013492, accuracy R^2: 98.65%\n",
      "step: 121, loss: 0.012669, accuracy R^2: 98.73%\n",
      "step: 122, loss: 0.011903, accuracy R^2: 98.81%\n",
      "step: 123, loss: 0.011198, accuracy R^2: 98.88%\n",
      "step: 124, loss: 0.010547, accuracy R^2: 98.95%\n",
      "step: 125, loss: 0.00995, accuracy R^2: 99.0%\n",
      "step: 126, loss: 0.009441, accuracy R^2: 99.06%\n",
      "step: 127, loss: 0.008942, accuracy R^2: 99.11%\n",
      "step: 128, loss: 0.008491, accuracy R^2: 99.15%\n",
      "step: 129, loss: 0.008067, accuracy R^2: 99.19%\n",
      "step: 130, loss: 0.007658, accuracy R^2: 99.23%\n",
      "step: 131, loss: 0.007308, accuracy R^2: 99.27%\n",
      "step: 132, loss: 0.00695, accuracy R^2: 99.3%\n",
      "step: 133, loss: 0.006629, accuracy R^2: 99.34%\n",
      "step: 134, loss: 0.006328, accuracy R^2: 99.37%\n",
      "step: 135, loss: 0.006029, accuracy R^2: 99.4%\n",
      "step: 136, loss: 0.005777, accuracy R^2: 99.42%\n",
      "step: 137, loss: 0.005516, accuracy R^2: 99.45%\n",
      "step: 138, loss: 0.005278, accuracy R^2: 99.47%\n",
      "step: 139, loss: 0.005059, accuracy R^2: 99.49%\n",
      "step: 140, loss: 0.004842, accuracy R^2: 99.52%\n",
      "step: 141, loss: 0.004653, accuracy R^2: 99.53%\n",
      "step: 142, loss: 0.004455, accuracy R^2: 99.55%\n",
      "step: 143, loss: 0.004291, accuracy R^2: 99.57%\n",
      "step: 144, loss: 0.004117, accuracy R^2: 99.59%\n",
      "step: 145, loss: 0.003965, accuracy R^2: 99.6%\n",
      "step: 146, loss: 0.003815, accuracy R^2: 99.62%\n",
      "step: 147, loss: 0.003675, accuracy R^2: 99.63%\n",
      "step: 148, loss: 0.003549, accuracy R^2: 99.65%\n",
      "step: 149, loss: 0.003414, accuracy R^2: 99.66%\n",
      "[[Value(data=1.0187591415095003, grad=0.009379570754750155)], [Value(data=-0.9335370854144212, grad=0.033231457292789424)], [Value(data=-1.057080915057983, grad=-0.02854045752899148)], [Value(data=0.9249884293615176, grad=-0.0375057853192412)]] [1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 7)\n",
    "%config InlineBackend.figure_format = 'svg'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x700 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"497.38125pt\" height=\"432.83625pt\" viewBox=\"0 0 497.38125 432.83625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-12-11T17:59:48.734090</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 432.83625 \nL 497.38125 432.83625 \nL 497.38125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 395.28 \nL 490.18125 395.28 \nL 490.18125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 64.072159 395.28 \nL 64.072159 7.2 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill: #262626\" transform=\"translate(60.890909 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 118.912454 395.28 \nL 118.912454 7.2 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g style=\"fill: #262626\" transform=\"translate(112.549954 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 173.752749 395.28 \nL 173.752749 7.2 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g style=\"fill: #262626\" transform=\"translate(167.390249 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 228.593044 395.28 \nL 228.593044 7.2 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g style=\"fill: #262626\" transform=\"translate(222.230544 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 283.433338 395.28 \nL 283.433338 7.2 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g style=\"fill: #262626\" transform=\"translate(277.070838 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 338.273633 395.28 \nL 338.273633 7.2 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g style=\"fill: #262626\" transform=\"translate(328.729883 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <path d=\"M 393.113928 395.28 \nL 393.113928 7.2 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g style=\"fill: #262626\" transform=\"translate(383.570178 409.878437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <path d=\"M 447.954223 395.28 \nL 447.954223 7.2 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140 -->\n      <g style=\"fill: #262626\" transform=\"translate(438.410473 409.878437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- Epoch -->\n     <g style=\"fill: #262626\" transform=\"translate(459.559375 423.556562)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path d=\"M 43.78125 378.775399 \nL 490.18125 378.775399 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 382.574618)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <path d=\"M 43.78125 312.252288 \nL 490.18125 312.252288 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 316.051507)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <path d=\"M 43.78125 245.729176 \nL 490.18125 245.729176 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 249.528395)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <path d=\"M 43.78125 179.206065 \nL 490.18125 179.206065 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 183.005284)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <path d=\"M 43.78125 112.682954 \nL 490.18125 112.682954 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 116.482173)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <path d=\"M 43.78125 46.159843 \nL 490.18125 46.159843 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 49.959061)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- MSE -->\n     <g style=\"fill: #262626\" transform=\"translate(14.798438 28.495312)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-4d\" d=\"M 628 4666 \nL 1569 4666 \nL 2759 1491 \nL 3956 4666 \nL 4897 4666 \nL 4897 0 \nL 4281 0 \nL 4281 4097 \nL 3078 897 \nL 2444 897 \nL 1241 4097 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4d\"/>\n      <use xlink:href=\"#DejaVuSans-53\" x=\"86.279297\"/>\n      <use xlink:href=\"#DejaVuSans-45\" x=\"149.755859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"PolyCollection_1\"/>\n   <g id=\"line2d_15\">\n    <path d=\"M 64.072159 24.84 \nL 72.298203 34.508435 \nL 80.524248 43.854019 \nL 91.492307 55.996093 \nL 135.364542 104.079511 \nL 146.332601 116.645165 \nL 154.558646 126.359554 \nL 162.78469 136.371464 \nL 171.010734 146.721015 \nL 179.236778 157.443257 \nL 187.462822 168.566048 \nL 195.688867 180.107205 \nL 203.914911 192.070918 \nL 212.140955 204.443506 \nL 220.366999 217.188762 \nL 231.335058 234.648223 \nL 250.529162 265.616084 \nL 261.497221 282.239977 \nL 269.723265 294.283062 \nL 277.949309 305.712887 \nL 283.433338 312.952966 \nL 288.917368 319.819546 \nL 294.401397 326.271644 \nL 299.885427 332.267628 \nL 305.369456 337.79746 \nL 310.853486 342.860616 \nL 316.337515 347.439317 \nL 321.821545 351.538535 \nL 327.305574 355.196008 \nL 332.789604 358.407379 \nL 338.273633 361.224656 \nL 343.757663 363.665318 \nL 349.241692 365.777228 \nL 354.725722 367.583175 \nL 360.209751 369.131404 \nL 365.693781 370.443948 \nL 371.17781 371.562428 \nL 376.66184 372.508255 \nL 384.887884 373.662615 \nL 393.113928 374.561631 \nL 401.339972 375.267155 \nL 412.308031 375.951327 \nL 426.018105 376.570331 \nL 445.212208 377.164804 \nL 469.890341 377.64 \nL 469.890341 377.64 \n\" clip-path=\"url(#pfd9c3863b7)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 395.28 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 490.18125 395.28 \nL 490.18125 7.2 \n\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 395.28 \nL 490.18125 395.28 \n\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 490.18125 7.2 \n\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfd9c3863b7\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"446.4\" height=\"388.08\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Epoch', loc='right')\n",
    "plt.ylabel('MSE', loc='top')\n",
    "sns.lineplot(loss_hist[1:], color='blue');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x700 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"497.38125pt\" height=\"432.83625pt\" viewBox=\"0 0 497.38125 432.83625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-12-11T17:59:48.916973</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 432.83625 \nL 497.38125 432.83625 \nL 497.38125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 395.28 \nL 490.18125 395.28 \nL 490.18125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 64.072159 395.28 \nL 64.072159 7.2 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill: #262626\" transform=\"translate(60.890909 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 118.544398 395.28 \nL 118.544398 7.2 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g style=\"fill: #262626\" transform=\"translate(112.181898 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 173.016637 395.28 \nL 173.016637 7.2 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g style=\"fill: #262626\" transform=\"translate(166.654137 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 227.488877 395.28 \nL 227.488877 7.2 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g style=\"fill: #262626\" transform=\"translate(221.126377 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 281.961116 395.28 \nL 281.961116 7.2 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g style=\"fill: #262626\" transform=\"translate(275.598616 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 336.433355 395.28 \nL 336.433355 7.2 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g style=\"fill: #262626\" transform=\"translate(326.889605 409.878437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <path d=\"M 390.905594 395.28 \nL 390.905594 7.2 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g style=\"fill: #262626\" transform=\"translate(381.361844 409.878437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <path d=\"M 445.377833 395.28 \nL 445.377833 7.2 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140 -->\n      <g style=\"fill: #262626\" transform=\"translate(435.834083 409.878437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- Epoch -->\n     <g style=\"fill: #262626\" transform=\"translate(459.559375 423.556562)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path d=\"M 43.78125 377.64 \nL 490.18125 377.64 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 381.439219)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <path d=\"M 43.78125 306.838315 \nL 490.18125 306.838315 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 310.637534)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <path d=\"M 43.78125 236.03663 \nL 490.18125 236.03663 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 239.835849)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <path d=\"M 43.78125 165.234945 \nL 490.18125 165.234945 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 169.034164)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <path d=\"M 43.78125 94.43326 \nL 490.18125 94.43326 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 98.232479)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <path d=\"M 43.78125 23.631575 \nL 490.18125 23.631575 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 27.430794)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- $R^2$ -->\n     <g style=\"fill: #262626\" transform=\"translate(14.798438 19.6)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-Oblique-52\" d=\"M 1613 4147 \nL 1294 2491 \nL 2106 2491 \nQ 2584 2491 2879 2755 \nQ 3175 3019 3175 3444 \nQ 3175 3784 2976 3965 \nQ 2778 4147 2406 4147 \nL 1613 4147 \nz\nM 2772 2241 \nQ 2972 2194 3105 2009 \nQ 3238 1825 3413 1275 \nL 3809 0 \nL 3144 0 \nL 2778 1197 \nQ 2638 1659 2453 1815 \nQ 2269 1972 1888 1972 \nL 1191 1972 \nL 806 0 \nL 172 0 \nL 1081 4666 \nL 2503 4666 \nQ 3150 4666 3495 4373 \nQ 3841 4081 3841 3531 \nQ 3841 3044 3547 2687 \nQ 3253 2331 2772 2241 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-Oblique-52\" transform=\"translate(0 0.765625)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(76.499193 39.046875)scale(0.7)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"PolyCollection_1\"/>\n   <g id=\"line2d_15\">\n    <path d=\"M 64.072159 377.64 \nL 83.137443 377.64 \nL 85.861055 376.833893 \nL 99.479115 360.798117 \nL 129.438846 325.781205 \nL 140.333294 312.690322 \nL 151.227742 299.207247 \nL 159.398578 288.76751 \nL 167.569414 277.996394 \nL 175.740249 266.852791 \nL 183.911085 255.301658 \nL 192.081921 243.316533 \nL 200.252757 230.882826 \nL 208.423593 218.001887 \nL 216.594429 204.695706 \nL 224.765265 191.011926 \nL 235.659712 172.31926 \nL 252.001384 144.06897 \nL 262.895832 126.375876 \nL 271.066668 113.558215 \nL 279.237504 101.393257 \nL 284.684728 93.687516 \nL 290.131952 86.379298 \nL 295.579176 79.512219 \nL 301.026399 73.130591 \nL 306.473623 67.245096 \nL 311.920847 61.856293 \nL 317.368071 56.983103 \nL 322.815295 52.620236 \nL 328.262519 48.727524 \nL 333.709743 45.309608 \nL 339.156967 42.311131 \nL 344.604191 39.713493 \nL 350.051415 37.465751 \nL 355.498639 35.543651 \nL 360.945863 33.895845 \nL 366.393086 32.498881 \nL 371.84031 31.308463 \nL 377.287534 30.301804 \nL 385.45837 29.073199 \nL 393.629206 28.11636 \nL 401.800042 27.36546 \nL 409.970878 26.797256 \nL 423.588938 26.092006 \nL 439.930609 25.499906 \nL 461.719505 24.982133 \nL 469.890341 24.84 \nL 469.890341 24.84 \n\" clip-path=\"url(#pfe6b80353e)\" style=\"fill: none; stroke: #ffa500; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 395.28 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 490.18125 395.28 \nL 490.18125 7.2 \n\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 395.28 \nL 490.18125 395.28 \n\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 490.18125 7.2 \n\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfe6b80353e\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"446.4\" height=\"388.08\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Epoch', loc='right')\n",
    "plt.ylabel(r'$R^2$', loc='top')\n",
    "sns.lineplot(acc_hist, color='orange');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Домашнее задание"
   ],
   "metadata": {
    "id": "n4maaWL5yg-f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Домашнее задание 1.** Доделать практику. Оформить код в три отдельных модуля `autograd`, `nn`, `train`"
   ],
   "metadata": {
    "id": "2yyK39RYo084"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Домашнее задание 2 (Опционально).** Создать свою функцию softmax, наследуемую от `torch.autograd.Function` и имплементировать forward и backward проход. Сравнить со стандартной функцией в Pytorch. \n",
    "[Создание функций](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html) [Софтмакс](https://congyuzhou.medium.com/softmax-3408fb42d55a)"
   ],
   "metadata": {
    "id": "FdzPyQ-hylKH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from torch.autograd import Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Softmax(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, vector):\n",
    "\n",
    "        denominator = 0\n",
    "        denominator = vector.exp().sum()\n",
    "        result = vector.exp() / denominator\n",
    "\n",
    "        grad = torch.zeros(len(result), len(result))\n",
    "\n",
    "        for i in range(len(grad)):\n",
    "            for j in range(len(result)):\n",
    "                if i == j:\n",
    "                    grad[i][j] = result[i] * (1 - result[j])\n",
    "                else:\n",
    "                    grad[i][j] = - result[i] * result[j]\n",
    "\n",
    "        ctx.save_for_backward(grad)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        print(ctx.saved_tensors)\n",
    "        grad, = ctx.saved_tensors\n",
    "        return grad.matmul(grad_output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0103, 0.0378, 0.0253, 0.9266], grad_fn=<SoftmaxBackward>)"
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor((1.1, 2.4, 2.0, 5.6), requires_grad=True)\n",
    "custom_output = Softmax.apply(input)\n",
    "custom_output.retain_grad()\n",
    "custom_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0102, -0.0004, -0.0003, -0.0095],\n",
      "        [-0.0004,  0.0363, -0.0010, -0.0350],\n",
      "        [-0.0003, -0.0010,  0.0247, -0.0235],\n",
      "        [-0.0095, -0.0350, -0.0235,  0.0680]]),)\n",
      "---\n",
      "data - tensor([0.0103, 0.0378, 0.0253, 0.9266])\n",
      "grad - tensor([ 0.0206, -1.9245, -1.9494,  1.8532])\n",
      "grad_fn - <torch.autograd.function.SoftmaxBackward object at 0x7f6ac0b9be20>\n",
      "req_grad - True\n",
      "is_leaf - False\n",
      "---\n",
      "data - tensor([1.1000, 2.4000, 2.0000, 5.6000])\n",
      "grad - tensor([-0.0162, -0.1329, -0.0897,  0.2389])\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n"
     ]
    }
   ],
   "source": [
    "true = torch.tensor((0.0, 1.0, 1.0, 0.0))\n",
    "loss = ((custom_output - true) ** 2).sum()\n",
    "loss.backward()\n",
    "show_tensor_params(custom_output)\n",
    "show_tensor_params(input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0103, 0.0378, 0.0253, 0.9266], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor((1.1, 2.4, 2.0, 5.6), requires_grad=True)\n",
    "sm = torch.nn.Softmax(dim=0)\n",
    "torch_output = sm(input)\n",
    "torch_output.retain_grad()\n",
    "torch_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "data - tensor([0.0103, 0.0378, 0.0253, 0.9266])\n",
      "grad - tensor([ 0.0206, -1.9245, -1.9494,  1.8532])\n",
      "grad_fn - <SoftmaxBackward0 object at 0x7f6ab947f460>\n",
      "req_grad - True\n",
      "is_leaf - False\n",
      "---\n",
      "data - tensor([1.1000, 2.4000, 2.0000, 5.6000])\n",
      "grad - tensor([-0.0162, -0.1329, -0.0897,  0.2389])\n",
      "grad_fn - None\n",
      "req_grad - True\n",
      "is_leaf - True\n"
     ]
    }
   ],
   "source": [
    "true = torch.tensor((0.0, 1.0, 1.0, 0.0))\n",
    "loss = ((torch_output - true) ** 2).sum()\n",
    "loss.backward()\n",
    "show_tensor_params(torch_output)\n",
    "show_tensor_params(input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Домашнее задание 3 (Опционально).** Добавить функцию софтмакс в собственну библиотеку автоматического дифференцирования. Сравнить с пунктом 2"
   ],
   "metadata": {
    "id": "3VPpRO6H6SHF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ваш код"
   ],
   "metadata": {
    "id": "2YJfxtqSphFs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Домашнее задание 4 (Опционально).** Добавить визуализацию обучения. Потом мы пройдем более подробно."
   ],
   "metadata": {
    "id": "nRRgw0HNsr_a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://docs.wandb.ai/guides/integrations/pytorch"
   ],
   "metadata": {
    "id": "W5AWW52REfn5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://docs.wandb.ai/ref/python/watch  "
   ],
   "metadata": {
    "id": "ekFfy3cWVOIW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://docs.wandb.ai/guides/track/jupyter"
   ],
   "metadata": {
    "id": "9G4SOp28ok0o"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install wandb"
   ],
   "metadata": {
    "id": "lumiR8oykL04"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!wandb login"
   ],
   "metadata": {
    "id": "Xw3c6P7BkP9b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "run = wandb.init(project=\"polynom_learning_\")"
   ],
   "metadata": {
    "id": "udPv0ufwkxOv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "id": "Xtpc9MAUodNs"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
