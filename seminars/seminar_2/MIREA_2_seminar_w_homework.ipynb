{"metadata":{"colab":{"provenance":[],"collapsed_sections":["MRuSrP7JQ00i","1b95Z8u7Q3OL"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Разбор практики 1.**","metadata":{"id":"RQ8rTFmQ0ueR"}},{"cell_type":"markdown","source":"## **Задача 2**. Cделать нейрон, соответствующий оператору НЕ.","metadata":{"id":"9P9bWaC9QQJm"}},{"cell_type":"code","source":"class Neuron(torch.nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.fc = torch.nn.Linear(1, 1, bias=True)\n\n  def forward(self, x):\n    return torch.heaviside(self.fc(x), torch.tensor([0.0]))","metadata":{"id":"Hh8sSJkEWNmT","execution":{"iopub.status.busy":"2022-12-08T15:49:29.257425Z","iopub.execute_input":"2022-12-08T15:49:29.257800Z","iopub.status.idle":"2022-12-08T15:49:29.264537Z","shell.execute_reply.started":"2022-12-08T15:49:29.257769Z","shell.execute_reply":"2022-12-08T15:49:29.263439Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"neuron = Neuron()\nneuron.fc.weight, neuron.fc.bias","metadata":{"id":"r9HoH1koVQXi","outputId":"e3020bb5-04c1-45cf-937a-77d6c2337325","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-12-08T15:49:29.271340Z","iopub.execute_input":"2022-12-08T15:49:29.271674Z","iopub.status.idle":"2022-12-08T15:49:29.286216Z","shell.execute_reply.started":"2022-12-08T15:49:29.271647Z","shell.execute_reply":"2022-12-08T15:49:29.285205Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(Parameter containing:\n tensor([[0.8901]], requires_grad=True),\n Parameter containing:\n tensor([0.0171], requires_grad=True))"},"metadata":{}}]},{"cell_type":"code","source":"neuron.fc.weight.data = torch.tensor([[-1.0]])\nneuron.fc.bias.data = torch.tensor([1.0])\nneuron.fc.weight, neuron.fc.bias","metadata":{"id":"MLmGhtWFTYlV","outputId":"9ca8cb0a-4683-44d6-e910-69e6908a587c","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-12-08T15:49:29.288588Z","iopub.execute_input":"2022-12-08T15:49:29.289075Z","iopub.status.idle":"2022-12-08T15:49:29.297482Z","shell.execute_reply.started":"2022-12-08T15:49:29.289012Z","shell.execute_reply":"2022-12-08T15:49:29.296494Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(Parameter containing:\n tensor([[-1.]], requires_grad=True),\n Parameter containing:\n tensor([1.], requires_grad=True))"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([0.0])\nneuron(x)","metadata":{"id":"UFr5InkDTf-r","outputId":"6504e778-9bd4-4c5f-c2f8-67d22bb522d5","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-12-08T15:49:29.299226Z","iopub.execute_input":"2022-12-08T15:49:29.300040Z","iopub.status.idle":"2022-12-08T15:49:29.326185Z","shell.execute_reply.started":"2022-12-08T15:49:29.299987Z","shell.execute_reply":"2022-12-08T15:49:29.325165Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([1.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([1.0])\nneuron(x)","metadata":{"id":"sXJqgPEwAwHa","outputId":"12c3a893-da2c-4b19-de63-0a803b132b38","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-12-08T15:49:29.327811Z","iopub.execute_input":"2022-12-08T15:49:29.328162Z","iopub.status.idle":"2022-12-08T15:49:29.335790Z","shell.execute_reply.started":"2022-12-08T15:49:29.328128Z","shell.execute_reply":"2022-12-08T15:49:29.334756Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"tensor([0.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Задача 3**. Cделать нейрон, соответствующий оператору И.","metadata":{"id":"TRxJxcRJQsMz"}},{"cell_type":"code","source":"class Neuron(torch.nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.fc = torch.nn.Linear(2, 1)\n\n  def forward(self, x):\n    return torch.heaviside(self.fc(x), torch.tensor([0.0]))","metadata":{"id":"7dvDtA7HX3V6","execution":{"iopub.status.busy":"2022-12-08T15:49:29.338655Z","iopub.execute_input":"2022-12-08T15:49:29.339468Z","iopub.status.idle":"2022-12-08T15:49:29.346407Z","shell.execute_reply.started":"2022-12-08T15:49:29.339434Z","shell.execute_reply":"2022-12-08T15:49:29.344939Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"neuron = Neuron()\nneuron.fc.weight, neuron.fc.bias","metadata":{"id":"olMqAnQtX5NQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d3b3ffe4-f637-4338-a46f-9db503a316ab","execution":{"iopub.status.busy":"2022-12-08T15:49:29.347872Z","iopub.execute_input":"2022-12-08T15:49:29.348825Z","iopub.status.idle":"2022-12-08T15:49:29.358885Z","shell.execute_reply.started":"2022-12-08T15:49:29.348702Z","shell.execute_reply":"2022-12-08T15:49:29.357585Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(Parameter containing:\n tensor([[-0.0271,  0.5017]], requires_grad=True),\n Parameter containing:\n tensor([0.2149], requires_grad=True))"},"metadata":{}}]},{"cell_type":"code","source":"neuron.fc.weight.data = torch.tensor([[1.0, 1.0]])\nneuron.fc.bias.data = torch.tensor([-1.5])\nneuron.fc.weight, neuron.fc.bias","metadata":{"id":"kAtwMX7HQ0aj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"53bb0196-ecaf-489c-858e-c3d420d454aa","execution":{"iopub.status.busy":"2022-12-08T15:49:29.360543Z","iopub.execute_input":"2022-12-08T15:49:29.361361Z","iopub.status.idle":"2022-12-08T15:49:29.371965Z","shell.execute_reply.started":"2022-12-08T15:49:29.361328Z","shell.execute_reply":"2022-12-08T15:49:29.371075Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(Parameter containing:\n tensor([[1., 1.]], requires_grad=True),\n Parameter containing:\n tensor([-1.5000], requires_grad=True))"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([0.0, 0.0])\nneuron(x)","metadata":{"id":"P27EdNkrXloh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"96718328-9f63-41df-8077-3791a2d6b905","execution":{"iopub.status.busy":"2022-12-08T15:49:29.373387Z","iopub.execute_input":"2022-12-08T15:49:29.374520Z","iopub.status.idle":"2022-12-08T15:49:29.381911Z","shell.execute_reply.started":"2022-12-08T15:49:29.374485Z","shell.execute_reply":"2022-12-08T15:49:29.380895Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor([0.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([1.0, 0.0 ])\nneuron(x)","metadata":{"outputId":"c04b6405-d7ae-4e49-a6c1-6f478572f17a","colab":{"base_uri":"https://localhost:8080/"},"id":"-BJc_ipGrei3","execution":{"iopub.status.busy":"2022-12-08T15:49:29.383427Z","iopub.execute_input":"2022-12-08T15:49:29.384538Z","iopub.status.idle":"2022-12-08T15:49:29.392046Z","shell.execute_reply.started":"2022-12-08T15:49:29.384451Z","shell.execute_reply":"2022-12-08T15:49:29.390993Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([0.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([0.0, 1.0 ])\nneuron(x)","metadata":{"outputId":"2788282c-a684-43c1-f219-3d16f45f14d3","colab":{"base_uri":"https://localhost:8080/"},"id":"KjVTdBf-rei5","execution":{"iopub.status.busy":"2022-12-08T15:49:29.393448Z","iopub.execute_input":"2022-12-08T15:49:29.394196Z","iopub.status.idle":"2022-12-08T15:49:29.402365Z","shell.execute_reply.started":"2022-12-08T15:49:29.394163Z","shell.execute_reply":"2022-12-08T15:49:29.401421Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([0.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([1.0, 1.0 ])\nneuron(x)","metadata":{"outputId":"9b335917-e009-479c-e75d-9d1565422b8e","colab":{"base_uri":"https://localhost:8080/"},"id":"kyomxCJUrei5","execution":{"iopub.status.busy":"2022-12-08T15:49:29.408310Z","iopub.execute_input":"2022-12-08T15:49:29.409211Z","iopub.status.idle":"2022-12-08T15:49:29.416929Z","shell.execute_reply.started":"2022-12-08T15:49:29.409168Z","shell.execute_reply":"2022-12-08T15:49:29.415975Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"tensor([1.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Задача 4**. Cделать нейрон, соответствующий оператору ИЛИ.","metadata":{"id":"MRuSrP7JQ00i"}},{"cell_type":"code","source":"neuron.fc.weight.data = torch.tensor([[1., 1.]])\nneuron.fc.bias.data = torch.tensor([-0.5])","metadata":{"id":"23RuhFqbQ24-","execution":{"iopub.status.busy":"2022-12-08T15:49:29.418412Z","iopub.execute_input":"2022-12-08T15:49:29.419719Z","iopub.status.idle":"2022-12-08T15:49:29.425364Z","shell.execute_reply.started":"2022-12-08T15:49:29.419589Z","shell.execute_reply":"2022-12-08T15:49:29.424356Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"x = torch.tensor([0.0, 0.0])\nneuron(x)","metadata":{"id":"i-BZHFqnXpLL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7105825d-66f2-48db-a250-8a3bfe6be45d","execution":{"iopub.status.busy":"2022-12-08T15:49:29.426951Z","iopub.execute_input":"2022-12-08T15:49:29.427479Z","iopub.status.idle":"2022-12-08T15:49:29.438498Z","shell.execute_reply.started":"2022-12-08T15:49:29.427443Z","shell.execute_reply":"2022-12-08T15:49:29.437413Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"tensor([0.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([1.0, 0.0 ])\nneuron(x)","metadata":{"outputId":"8181961c-7669-4a37-c4ce-1277622af170","colab":{"base_uri":"https://localhost:8080/"},"id":"TZuFtRlvyixQ","execution":{"iopub.status.busy":"2022-12-08T15:49:29.440045Z","iopub.execute_input":"2022-12-08T15:49:29.440919Z","iopub.status.idle":"2022-12-08T15:49:29.448663Z","shell.execute_reply.started":"2022-12-08T15:49:29.440886Z","shell.execute_reply":"2022-12-08T15:49:29.447274Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"tensor([1.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([0.0, 1.0 ])\nneuron(x)","metadata":{"outputId":"26449834-8084-4c6a-a696-141449d0622f","colab":{"base_uri":"https://localhost:8080/"},"id":"jyu88Kg0yixR","execution":{"iopub.status.busy":"2022-12-08T15:49:29.450607Z","iopub.execute_input":"2022-12-08T15:49:29.451300Z","iopub.status.idle":"2022-12-08T15:49:29.458887Z","shell.execute_reply.started":"2022-12-08T15:49:29.451266Z","shell.execute_reply":"2022-12-08T15:49:29.457763Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"tensor([1.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.tensor([1.0, 1.0 ])\nneuron(x)","metadata":{"outputId":"0100e5f4-c3a6-4188-9c5b-42cf823eb1e3","colab":{"base_uri":"https://localhost:8080/"},"id":"r2OhYEC7yixS","execution":{"iopub.status.busy":"2022-12-08T15:49:29.460388Z","iopub.execute_input":"2022-12-08T15:49:29.461120Z","iopub.status.idle":"2022-12-08T15:49:29.468479Z","shell.execute_reply.started":"2022-12-08T15:49:29.461085Z","shell.execute_reply":"2022-12-08T15:49:29.467410Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"tensor([1.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Задача 5**. Cделать нейрон, соответствующий оператору XOR.","metadata":{"id":"1b95Z8u7Q3OL"}},{"cell_type":"code","source":"neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\nneuron.fc.bias.data = torch.tensor([0.0])","metadata":{"id":"hWP7ee7tjCGv","execution":{"iopub.status.busy":"2022-12-08T15:49:29.470433Z","iopub.execute_input":"2022-12-08T15:49:29.471205Z","iopub.status.idle":"2022-12-08T15:49:29.476441Z","shell.execute_reply.started":"2022-12-08T15:49:29.471169Z","shell.execute_reply":"2022-12-08T15:49:29.475539Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"x = torch.tensor([0.0, 0.0])\nneuron(x)","metadata":{"id":"HgDrZ7PBjGwJ","execution":{"iopub.status.busy":"2022-12-08T15:49:29.477883Z","iopub.execute_input":"2022-12-08T15:49:29.478636Z","iopub.status.idle":"2022-12-08T15:49:29.486822Z","shell.execute_reply.started":"2022-12-08T15:49:29.478602Z","shell.execute_reply":"2022-12-08T15:49:29.486045Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor([0.], grad_fn=<NotImplemented>)"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Занятие 2.**","metadata":{"id":"zjM7DFps2rBi"}},{"cell_type":"markdown","source":"# [Pytorch autograd](https://pytorch.org/docs/stable/autograd.html)","metadata":{"id":"KlS1ciOPBg7g"}},{"cell_type":"markdown","source":"[Tutorial](https://www.youtube.com/watch?v=MswxJw-8PvE)\n\n[Slides](https://app.diagrams.net/#G1bq3akhmA5DGRCiFYJfNPSn7il2wvCkEY)\n\n[Torch C++ Binary operations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp)\n\n[Torch C++ Activations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/Activation.cpp)","metadata":{"id":"kP06X1SrzLlm"}},{"cell_type":"code","source":"import torch","metadata":{"id":"alR-VHX_gnQK","execution":{"iopub.status.busy":"2022-12-08T15:49:29.488303Z","iopub.execute_input":"2022-12-08T15:49:29.489095Z","iopub.status.idle":"2022-12-08T15:49:29.494539Z","shell.execute_reply.started":"2022-12-08T15:49:29.489050Z","shell.execute_reply":"2022-12-08T15:49:29.493946Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def show_tensor_params(*tensors):\n  for x in tensors:\n    print('---')\n    print(f\"data - {x.data}\")\n    print(f\"grad - {x.grad}\")\n    print(f\"grad_fn - {x.grad_fn}\")\n    print(f\"req_grad - {x.requires_grad}\")\n    print(f\"is_leaf - {x.is_leaf}\")","metadata":{"id":"ipOjjh8OCk4u","execution":{"iopub.status.busy":"2022-12-08T15:49:29.495889Z","iopub.execute_input":"2022-12-08T15:49:29.496525Z","iopub.status.idle":"2022-12-08T15:49:29.504268Z","shell.execute_reply.started":"2022-12-08T15:49:29.496488Z","shell.execute_reply":"2022-12-08T15:49:29.503280Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"x = torch.tensor(5.0)\nshow_tensor_params(x)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXas0qEnybl9","outputId":"5e4bcc93-2541-4f5d-adf6-578ad58e391e","execution":{"iopub.status.busy":"2022-12-08T15:49:29.505724Z","iopub.execute_input":"2022-12-08T15:49:29.506493Z","iopub.status.idle":"2022-12-08T15:49:29.515606Z","shell.execute_reply.started":"2022-12-08T15:49:29.506459Z","shell.execute_reply":"2022-12-08T15:49:29.514549Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"---\ndata - 5.0\ngrad - None\ngrad_fn - None\nreq_grad - False\nis_leaf - True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"All Tensors that have **requires_grad** which is **False** will be leaf Tensors by convention.\n\nFor Tensors that have **requires_grad** which is **True**, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so **grad_fn** is None.\n\nOnly leaf Tensors will have their **grad** populated during a call to backward(). To get grad populated for non-leaf Tensors, you can use retain_grad().[[Link]](https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf)","metadata":{"id":"NuymHxbjzDfP"}},{"cell_type":"code","source":"#Slide A4\na = torch.tensor(2.0, requires_grad=True)\nb = torch.tensor(3.0)\nc = a*b\n\nc.backward()\n# (2 * c).backward()","metadata":{"id":"O5NE4zRPyqTT","execution":{"iopub.status.busy":"2022-12-08T15:49:29.517261Z","iopub.execute_input":"2022-12-08T15:49:29.518008Z","iopub.status.idle":"2022-12-08T15:49:29.527555Z","shell.execute_reply.started":"2022-12-08T15:49:29.517973Z","shell.execute_reply":"2022-12-08T15:49:29.526844Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"show_tensor_params(a, b, c)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-TbdvmH-oaM","outputId":"4a390c62-06af-4ee1-f086-09ca09c2d70b","execution":{"iopub.status.busy":"2022-12-08T15:49:29.529221Z","iopub.execute_input":"2022-12-08T15:49:29.530134Z","iopub.status.idle":"2022-12-08T15:49:29.536977Z","shell.execute_reply.started":"2022-12-08T15:49:29.530095Z","shell.execute_reply":"2022-12-08T15:49:29.535900Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"---\ndata - 2.0\ngrad - 3.0\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n---\ndata - 3.0\ngrad - None\ngrad_fn - None\nreq_grad - False\nis_leaf - True\n---\ndata - 6.0\ngrad - None\ngrad_fn - <MulBackward0 object at 0x7f715a920e50>\nreq_grad - True\nis_leaf - False\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /usr/local/src/pytorch/build/aten/src/ATen/core/TensorBody.h:470.)\n  return self._grad\n","output_type":"stream"}]},{"cell_type":"code","source":"#Slide Simple5","metadata":{"id":"NqUcFO2rCXni","execution":{"iopub.status.busy":"2022-12-08T15:49:29.538674Z","iopub.execute_input":"2022-12-08T15:49:29.539501Z","iopub.status.idle":"2022-12-08T15:49:29.543874Z","shell.execute_reply.started":"2022-12-08T15:49:29.539466Z","shell.execute_reply":"2022-12-08T15:49:29.542856Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"a = torch.tensor(2.0, requires_grad=True)\nb = torch.tensor(3.0, requires_grad=True)\nc = a*b\nd = torch.tensor(4.0, requires_grad=True)\ne = c*d\n\nc.retain_grad()\ne.retain_grad()\ne.backward()","metadata":{"id":"gYTsuKc3Fn8r","execution":{"iopub.status.busy":"2022-12-08T15:49:29.545416Z","iopub.execute_input":"2022-12-08T15:49:29.546173Z","iopub.status.idle":"2022-12-08T15:49:29.554536Z","shell.execute_reply.started":"2022-12-08T15:49:29.546139Z","shell.execute_reply":"2022-12-08T15:49:29.553838Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"show_tensor_params(a, b, c, d, e)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"egTBJvIBF5EO","outputId":"9efd5963-c845-441f-98bd-e2bfccf5f864","execution":{"iopub.status.busy":"2022-12-08T15:49:29.556103Z","iopub.execute_input":"2022-12-08T15:49:29.556770Z","iopub.status.idle":"2022-12-08T15:49:29.563895Z","shell.execute_reply.started":"2022-12-08T15:49:29.556735Z","shell.execute_reply":"2022-12-08T15:49:29.563041Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"---\ndata - 2.0\ngrad - 12.0\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n---\ndata - 3.0\ngrad - 8.0\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n---\ndata - 6.0\ngrad - 4.0\ngrad_fn - <MulBackward0 object at 0x7f72050169d0>\nreq_grad - True\nis_leaf - False\n---\ndata - 4.0\ngrad - 6.0\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n---\ndata - 24.0\ngrad - 1.0\ngrad_fn - <MulBackward0 object at 0x7f715a8fc210>\nreq_grad - True\nis_leaf - False\n","output_type":"stream"}]},{"cell_type":"code","source":"#In place 1\na = torch.tensor(2.0, requires_grad=True)\nb = torch.tensor(3.0, requires_grad=True)\nc = a*b\nd = torch.tensor(4.0, requires_grad=True)\ne = c*d\nc += 1\n\ntry:\n    e.backward()\nexcept RuntimeError as re:\n    print(re)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"W5Cs2_REGgOS","outputId":"052158cf-8dba-440f-9e54-e42d5f8cc019","execution":{"iopub.status.busy":"2022-12-08T15:50:20.530529Z","iopub.execute_input":"2022-12-08T15:50:20.530900Z","iopub.status.idle":"2022-12-08T15:50:20.544606Z","shell.execute_reply.started":"2022-12-08T15:50:20.530870Z","shell.execute_reply":"2022-12-08T15:50:20.543254Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).\n","output_type":"stream"}]},{"cell_type":"code","source":"print(c._version)\nprint(d._version)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-WeqfWzYGhKG","outputId":"fff4c374-1755-4cd9-89c1-490bc49a9be2","execution":{"iopub.status.busy":"2022-12-08T15:50:24.694920Z","iopub.execute_input":"2022-12-08T15:50:24.695616Z","iopub.status.idle":"2022-12-08T15:50:24.701439Z","shell.execute_reply.started":"2022-12-08T15:50:24.695580Z","shell.execute_reply":"2022-12-08T15:50:24.700279Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"1\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"#In place 2\na = torch.tensor(2.0, requires_grad=True)\nb = torch.tensor(3.0, requires_grad=True)\nc = a*b\nd = torch.tensor(4.0, requires_grad=True)\ne = c+d\nc += 1\n\ne.backward()","metadata":{"id":"iLZ3Z4qIH4J4","execution":{"iopub.status.busy":"2022-12-08T15:50:26.673055Z","iopub.execute_input":"2022-12-08T15:50:26.673735Z","iopub.status.idle":"2022-12-08T15:50:26.681072Z","shell.execute_reply.started":"2022-12-08T15:50:26.673699Z","shell.execute_reply":"2022-12-08T15:50:26.680149Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(c._version)\nprint(d._version)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ySSjlRUIH0e","outputId":"93759314-cebe-41d2-882c-b59ad2043f2f","execution":{"iopub.status.busy":"2022-12-08T15:50:27.725391Z","iopub.execute_input":"2022-12-08T15:50:27.725760Z","iopub.status.idle":"2022-12-08T15:50:27.731092Z","shell.execute_reply.started":"2022-12-08T15:50:27.725728Z","shell.execute_reply":"2022-12-08T15:50:27.730091Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"1\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"#In place 3\na = torch.tensor(2.0, requires_grad=True)\nb = torch.tensor(3.0, requires_grad=True)\nc = a*b\nd = torch.tensor(4.0, requires_grad=True)\ne = c+d\nc = c + 1\n\ne.backward()","metadata":{"id":"KUD8tZEh5v1V","execution":{"iopub.status.busy":"2022-12-08T15:50:28.763750Z","iopub.execute_input":"2022-12-08T15:50:28.764294Z","iopub.status.idle":"2022-12-08T15:50:28.772128Z","shell.execute_reply.started":"2022-12-08T15:50:28.764258Z","shell.execute_reply":"2022-12-08T15:50:28.770121Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"print(c._version)\nprint(d._version)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f64d6d43-160e-45c5-e256-457b11220314","id":"3nSzWKz85v1Y","execution":{"iopub.status.busy":"2022-12-08T15:50:30.091499Z","iopub.execute_input":"2022-12-08T15:50:30.091845Z","iopub.status.idle":"2022-12-08T15:50:30.097669Z","shell.execute_reply.started":"2022-12-08T15:50:30.091814Z","shell.execute_reply":"2022-12-08T15:50:30.096669Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"0\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"# отвязка от графа\nk = e.detach()","metadata":{"id":"4jbSqPGkILEw","execution":{"iopub.status.busy":"2022-12-08T15:50:30.845864Z","iopub.execute_input":"2022-12-08T15:50:30.846465Z","iopub.status.idle":"2022-12-08T15:50:30.851061Z","shell.execute_reply.started":"2022-12-08T15:50:30.846425Z","shell.execute_reply":"2022-12-08T15:50:30.849845Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"k.storage == e.storage","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLKUQ08AJhZT","outputId":"b2465faa-85e9-4e53-fa3f-80be11974202","execution":{"iopub.status.busy":"2022-12-08T15:50:31.562039Z","iopub.execute_input":"2022-12-08T15:50:31.563222Z","iopub.status.idle":"2022-12-08T15:50:31.571748Z","shell.execute_reply.started":"2022-12-08T15:50:31.563186Z","shell.execute_reply":"2022-12-08T15:50:31.570648Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"show_tensor_params(e, k)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eqo-PW2kJkaG","outputId":"289035b8-cfd5-4b70-b47f-b1dc5e5c184c","execution":{"iopub.status.busy":"2022-12-08T15:50:32.654849Z","iopub.execute_input":"2022-12-08T15:50:32.655408Z","iopub.status.idle":"2022-12-08T15:50:32.667588Z","shell.execute_reply.started":"2022-12-08T15:50:32.655355Z","shell.execute_reply":"2022-12-08T15:50:32.666323Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"---\ndata - 10.0\ngrad - None\ngrad_fn - <AddBackward0 object at 0x7f7158f59910>\nreq_grad - True\nis_leaf - False\n---\ndata - 10.0\ngrad - None\ngrad_fn - None\nreq_grad - False\nis_leaf - True\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /usr/local/src/pytorch/build/aten/src/ATen/core/TensorBody.h:470.)\n  return self._grad\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Создание собственной библиотеки автоматического дифференцирования","metadata":{"id":"B8urvcsAKi62"}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"txwYkEHMftme","execution":{"iopub.status.busy":"2022-12-08T15:50:36.532897Z","iopub.execute_input":"2022-12-08T15:50:36.533595Z","iopub.status.idle":"2022-12-08T15:50:36.540044Z","shell.execute_reply.started":"2022-12-08T15:50:36.533555Z","shell.execute_reply":"2022-12-08T15:50:36.538978Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### Простой пример","metadata":{"id":"urGQXw9GgdQt"}},{"cell_type":"code","source":"def f(x):\n  return 3*x**2 - 4*x + 5","metadata":{"id":"bPNsEPbZfwXm","execution":{"iopub.status.busy":"2022-12-08T15:50:38.736785Z","iopub.execute_input":"2022-12-08T15:50:38.737163Z","iopub.status.idle":"2022-12-08T15:50:38.742376Z","shell.execute_reply.started":"2022-12-08T15:50:38.737132Z","shell.execute_reply":"2022-12-08T15:50:38.740877Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"f(3.0)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKMjYubGfzo5","outputId":"e4b624fd-bf9e-40d5-e390-d16bdf2ecaee","execution":{"iopub.status.busy":"2022-12-08T15:50:41.065446Z","iopub.execute_input":"2022-12-08T15:50:41.065805Z","iopub.status.idle":"2022-12-08T15:50:41.073171Z","shell.execute_reply.started":"2022-12-08T15:50:41.065773Z","shell.execute_reply":"2022-12-08T15:50:41.071940Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"20.0"},"metadata":{}}]},{"cell_type":"code","source":"xs = np.arange(-5, 5, 0.25)\nys = f(xs)\nplt.plot(xs, ys);","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"2Mufja5Mf2dD","outputId":"882942ce-e100-4e94-ab16-66df4a91bcd9","execution":{"iopub.status.busy":"2022-12-08T15:50:42.225113Z","iopub.execute_input":"2022-12-08T15:50:42.225897Z","iopub.status.idle":"2022-12-08T15:50:42.408917Z","shell.execute_reply.started":"2022-12-08T15:50:42.225857Z","shell.execute_reply":"2022-12-08T15:50:42.407941Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"h = 0.000001\nx = 2\n(f(x + h) - f(x))/h","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzRAdjhFgGo8","outputId":"80f5b90a-0446-4b37-b728-c6a0339c657f","execution":{"iopub.status.busy":"2022-12-08T15:50:44.037302Z","iopub.execute_input":"2022-12-08T15:50:44.037665Z","iopub.status.idle":"2022-12-08T15:50:44.044006Z","shell.execute_reply.started":"2022-12-08T15:50:44.037633Z","shell.execute_reply":"2022-12-08T15:50:44.043044Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"8.000003001384925"},"metadata":{}}]},{"cell_type":"markdown","source":"### Более сложный пример","metadata":{"id":"dOszwXaTgkd4"}},{"cell_type":"code","source":"a = 2.0\nb = -3.0\nc = 10.0\nd = a*b + c\nprint(d)","metadata":{"id":"BOzPl8NWghve","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa8691ab-c4d2-4b94-d016-145849dd8d30","execution":{"iopub.status.busy":"2022-12-08T15:50:45.134053Z","iopub.execute_input":"2022-12-08T15:50:45.135100Z","iopub.status.idle":"2022-12-08T15:50:45.141375Z","shell.execute_reply.started":"2022-12-08T15:50:45.135053Z","shell.execute_reply":"2022-12-08T15:50:45.140087Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"h = 0.0001\n\n# inputs\na = 2.0\nb = -3.0\nc = 10.0\n\nd1 = a*b + c\nc += h\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2 - d1)/h)\n\nd1 = a*b + c\na += h\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2 - d1)/h)\n\nd1 = a*b + c\nb += h\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2 - d1)/h)","metadata":{"id":"P9Xx4_omgrkm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fca0e3f8-d66c-45f3-b9f0-7e4464d36c62","execution":{"iopub.status.busy":"2022-12-08T15:50:45.695698Z","iopub.execute_input":"2022-12-08T15:50:45.696353Z","iopub.status.idle":"2022-12-08T15:50:45.705143Z","shell.execute_reply.started":"2022-12-08T15:50:45.696312Z","shell.execute_reply":"2022-12-08T15:50:45.704079Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"d1 4.0\nd2 4.0001\nslope 0.9999999999976694\nd1 4.0001\nd2 3.9997999999999987\nslope -3.000000000010772\nd1 3.9997999999999987\nd2 4.00000001\nslope 2.0001000000124947\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{"id":"wle8vv7_grKJ"}},{"cell_type":"markdown","source":"https://pytorch.org/tutorials/beginner/examples_autograd/polynomial_custom_function.html","metadata":{"id":"dlDJrMMsOgNh"}},{"cell_type":"code","source":"from torch.autograd import Function","metadata":{"id":"sPyPkdq5RH94","execution":{"iopub.status.busy":"2022-12-08T15:50:48.109427Z","iopub.execute_input":"2022-12-08T15:50:48.109885Z","iopub.status.idle":"2022-12-08T15:50:48.116809Z","shell.execute_reply.started":"2022-12-08T15:50:48.109838Z","shell.execute_reply":"2022-12-08T15:50:48.115855Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"class Exp(Function):\n  \"\"\"\n    We can implement our own custom autograd Functions by subclassing\n    torch.autograd.Function and implementing the forward and backward passes\n    which operate on Tensors.\n    \"\"\"\n\n  @staticmethod\n  def forward(ctx, i):\n    \"\"\"\n        In the forward pass we receive a Tensor containing the input and return\n        a Tensor containing the output. ctx is a context object that can be used\n        to stash information for backward computation. You can cache arbitrary\n        objects for use in the backward pass using the ctx.save_for_backward method.\n    \"\"\"\n    result = i.exp()\n    ctx.save_for_backward(result)\n    return result\n\n  @staticmethod\n  def backward(ctx, grad_output):\n    \"\"\"\n        In the backward pass we receive a Tensor containing the gradient of the loss\n        with respect to the output, and we need to compute the gradient of the loss\n        with respect to the input.\n    \"\"\"\n    print(ctx.saved_tensors)\n    result, = ctx.saved_tensors\n    return grad_output * result","metadata":{"id":"F5-hnsEiPIz9","execution":{"iopub.status.busy":"2022-12-08T15:53:39.138335Z","iopub.execute_input":"2022-12-08T15:53:39.138842Z","iopub.status.idle":"2022-12-08T15:53:39.148477Z","shell.execute_reply.started":"2022-12-08T15:53:39.138792Z","shell.execute_reply":"2022-12-08T15:53:39.147328Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Use it by calling the apply method\ninput = torch.tensor(2.0, requires_grad=True)\noutput = Exp.apply(input)\noutput","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"elaOA8bdRiMc","outputId":"be8842b1-682f-4249-dd66-49961d4a93a8","execution":{"iopub.status.busy":"2022-12-08T15:53:41.187644Z","iopub.execute_input":"2022-12-08T15:53:41.188008Z","iopub.status.idle":"2022-12-08T15:53:41.200265Z","shell.execute_reply.started":"2022-12-08T15:53:41.187974Z","shell.execute_reply":"2022-12-08T15:53:41.199234Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"tensor(7.3891, grad_fn=<ExpBackward>)"},"metadata":{}}]},{"cell_type":"code","source":"import math\nmath.exp(2.0)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlcZLt-RSGgG","outputId":"2ba81786-2183-4de7-ae7d-bd92ee5234f1","execution":{"iopub.status.busy":"2022-12-08T15:53:45.630088Z","iopub.execute_input":"2022-12-08T15:53:45.630446Z","iopub.status.idle":"2022-12-08T15:53:45.637576Z","shell.execute_reply.started":"2022-12-08T15:53:45.630414Z","shell.execute_reply":"2022-12-08T15:53:45.636355Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"7.38905609893065"},"metadata":{}}]},{"cell_type":"code","source":"output.backward()\nshow_tensor_params(output)\nshow_tensor_params(input)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Om6dn414SQeA","outputId":"2021d2ec-917e-4da2-8ce7-0fca5b549dfc","execution":{"iopub.status.busy":"2022-12-08T15:53:48.671570Z","iopub.execute_input":"2022-12-08T15:53:48.672152Z","iopub.status.idle":"2022-12-08T15:53:48.680246Z","shell.execute_reply.started":"2022-12-08T15:53:48.672107Z","shell.execute_reply":"2022-12-08T15:53:48.678918Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"(tensor(7.3891, grad_fn=<ExpBackward>),)\n---\ndata - 7.389056205749512\ngrad - None\ngrad_fn - <torch.autograd.function.ExpBackward object at 0x7f71588d4150>\nreq_grad - True\nis_leaf - False\n---\ndata - 2.0\ngrad - 7.389056205749512\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Задание**: реализуйте backward для Polynomial 0.5 * (5 * input ** 3 - 3 * input)","metadata":{"id":"d_14IqfeSnLM"}},{"cell_type":"code","source":"import torch\n\n\nclass Polynomial(torch.autograd.Function):\n    \"\"\"\n    We can implement our own custom autograd Functions by subclassing\n    torch.autograd.Function and implementing the forward and backward passes\n    which operate on Tensors.\n    \"\"\"\n\n    @staticmethod\n    def forward(ctx, input):\n        \"\"\"\n        In the forward pass we receive a Tensor containing the input and return\n        a Tensor containing the output. ctx is a context object that can be used\n        to stash information for backward computation. You can cache arbitrary\n        objects for use in the backward pass using the ctx.save_for_backward method.\n        \"\"\"\n        result = 0.5 * (5 * input ** 3 - 3 * input)\n        grad = 7.5 * input ** 2 - 1.5\n        ctx.save_for_backward(grad)\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        \"\"\"\n        In the backward pass we receive a Tensor containing the gradient of the loss\n        with respect to the output, and we need to compute the gradient of the loss\n        with respect to the input.\n        \"\"\"\n        print(ctx.saved_tensors)\n        grad, = ctx.saved_tensors\n        return grad_output * grad\n        ","metadata":{"id":"i5cNegVYOd8u","execution":{"iopub.status.busy":"2022-12-08T15:57:46.093868Z","iopub.execute_input":"2022-12-08T15:57:46.094966Z","iopub.status.idle":"2022-12-08T15:57:46.102129Z","shell.execute_reply.started":"2022-12-08T15:57:46.094912Z","shell.execute_reply":"2022-12-08T15:57:46.101071Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"input = torch.tensor(2.0, requires_grad=True)\nPolynomial.apply(input)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZERCX7g_1WS","outputId":"5f2b0174-3a37-4c7d-a7b5-25bd97d1c0c5","execution":{"iopub.status.busy":"2022-12-08T15:57:48.369655Z","iopub.execute_input":"2022-12-08T15:57:48.370031Z","iopub.status.idle":"2022-12-08T15:57:48.379752Z","shell.execute_reply.started":"2022-12-08T15:57:48.369984Z","shell.execute_reply":"2022-12-08T15:57:48.378767Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"tensor(17., grad_fn=<PolynomialBackward>)"},"metadata":{}}]},{"cell_type":"code","source":"p = Polynomial.apply(input)\np.backward()\nshow_tensor_params(input)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y5Nw3ByaAfsS","outputId":"1f9272dc-ac07-40f6-9847-06792331a342","execution":{"iopub.status.busy":"2022-12-08T15:57:49.202272Z","iopub.execute_input":"2022-12-08T15:57:49.202626Z","iopub.status.idle":"2022-12-08T15:57:49.209783Z","shell.execute_reply.started":"2022-12-08T15:57:49.202594Z","shell.execute_reply":"2022-12-08T15:57:49.208601Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"(tensor(28.5000),)\n---\ndata - 2.0\ngrad - 28.5\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n","output_type":"stream"}]},{"cell_type":"code","source":"input_tensor = torch.tensor(2.0, requires_grad=True)\ne = Exp.apply(input_tensor)\np = Polynomial.apply(e)\nprint(p)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:01:52.021807Z","iopub.execute_input":"2022-12-08T16:01:52.022226Z","iopub.status.idle":"2022-12-08T16:01:52.029856Z","shell.execute_reply.started":"2022-12-08T16:01:52.022195Z","shell.execute_reply":"2022-12-08T16:01:52.028824Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"tensor(997.4885, grad_fn=<PolynomialBackward>)\n","output_type":"stream"}]},{"cell_type":"code","source":"p.backward()\nshow_tensor_params(input_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:01:52.605669Z","iopub.execute_input":"2022-12-08T16:01:52.606010Z","iopub.status.idle":"2022-12-08T16:01:52.613283Z","shell.execute_reply.started":"2022-12-08T16:01:52.605972Z","shell.execute_reply":"2022-12-08T16:01:52.612238Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"(tensor(407.9861),)\n(tensor(7.3891, grad_fn=<ExpBackward>),)\n---\ndata - 2.0\ngrad - 3014.632568359375\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n","output_type":"stream"}]},{"cell_type":"code","source":"input_tensor = torch.tensor(2.0, requires_grad=True)\ne = Exp.apply(input_tensor)\ne = Exp.apply(e)\nprint(e)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:03:13.301352Z","iopub.execute_input":"2022-12-08T16:03:13.301708Z","iopub.status.idle":"2022-12-08T16:03:13.309658Z","shell.execute_reply.started":"2022-12-08T16:03:13.301678Z","shell.execute_reply":"2022-12-08T16:03:13.308711Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"tensor(1618.1782, grad_fn=<ExpBackward>)\n","output_type":"stream"}]},{"cell_type":"code","source":"e.backward()\nshow_tensor_params(input_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:03:15.063827Z","iopub.execute_input":"2022-12-08T16:03:15.064494Z","iopub.status.idle":"2022-12-08T16:03:15.071730Z","shell.execute_reply.started":"2022-12-08T16:03:15.064456Z","shell.execute_reply":"2022-12-08T16:03:15.070415Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"(tensor(1618.1782, grad_fn=<ExpBackward>),)\n(tensor(7.3891, grad_fn=<ExpBackward>),)\n---\ndata - 2.0\ngrad - 11956.8095703125\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n","output_type":"stream"}]},{"cell_type":"code","source":"input_tensor = torch.tensor(2.0, requires_grad=True)\nexp = Exp()\ne = exp.apply(input_tensor)\ne = exp.apply(e)\nprint(e)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:06:33.887380Z","iopub.execute_input":"2022-12-08T16:06:33.887742Z","iopub.status.idle":"2022-12-08T16:06:33.895569Z","shell.execute_reply.started":"2022-12-08T16:06:33.887711Z","shell.execute_reply":"2022-12-08T16:06:33.894558Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"tensor(1618.1782, grad_fn=<ExpBackward>)\n","output_type":"stream"}]},{"cell_type":"code","source":"e.backward()\nshow_tensor_params(input_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:06:40.462821Z","iopub.execute_input":"2022-12-08T16:06:40.463812Z","iopub.status.idle":"2022-12-08T16:06:40.471069Z","shell.execute_reply.started":"2022-12-08T16:06:40.463778Z","shell.execute_reply":"2022-12-08T16:06:40.469961Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"(tensor(1618.1782, grad_fn=<ExpBackward>),)\n(tensor(7.3891, grad_fn=<ExpBackward>),)\n---\ndata - 2.0\ngrad - 11956.8095703125\ngrad_fn - None\nreq_grad - True\nis_leaf - True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Практическое задание: написать собственный движок автоматического дифференцирования, а именно: реализовать","metadata":{"id":"fA2PNhudUNij"}},{"cell_type":"code","source":"class Value:\n    \"\"\" stores a single scalar value and its gradient \"\"\"\n\n    def __init__(self, data, _children=(), _op=''):\n        self.data = data\n        self.grad = 0\n        # internal variables used for autograd graph construction\n        self._backward = lambda: None # function \n        self._prev = set(_children) # set of Value objects\n        self._op = _op # the op that produced this node, string ('+', '-', ....)\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data)\n\n        def _backward():\n            self.grad = 1\n            other.grad = 1\n        out._backward = _backward\n\n        return out\n\n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(other.data * self.data)\n\n        def _backward():\n            self.grad += other.data\n            other.grad += self.data\n        out._backward = _backward\n\n        return out\n\n    def __pow__(self, other):\n        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n        out = Value(self.data ** other)\n\n        def _backward():\n            self.grad += other * self.data ** (other - 1)\n        out._backward = _backward\n\n        return out\n\n    def relu(self):\n        out = Value(self.data if self.data > 0 else 0)\n\n        def _backward():\n            self.grad += 1 if self.data > 0 else 0\n        out._backward = _backward\n\n        return out\n\n    def backward(self):\n\n        # topological order all of the children in the graph\n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        build_topo(self)\n\n        # go one variable at a time and apply the chain rule to get its gradient\n        self.grad = 1\n        for v in reversed(topo):\n            v._backward()\n\n    def __neg__(self): # -self\n        return self * -1\n\n    def __radd__(self, other): # other + self\n        return self + other\n\n    def __sub__(self, other): # self - other\n        return self + (-other)\n\n    def __rsub__(self, other): # other - self\n        return other + (-self)\n\n    def __rmul__(self, other): # other * self\n        return self * other\n\n    def __truediv__(self, other): # self / other\n        return self * other**-1\n\n    def __rtruediv__(self, other): # other / self\n        return other * self**-1\n\n    def __repr__(self):\n        return f\"Value(data={self.data}, grad={self.grad})\"","metadata":{"id":"chDdD9oSUlUJ","scrolled":true,"execution":{"iopub.status.busy":"2022-12-08T16:36:43.175567Z","iopub.execute_input":"2022-12-08T16:36:43.175926Z","iopub.status.idle":"2022-12-08T16:36:43.193195Z","shell.execute_reply.started":"2022-12-08T16:36:43.175894Z","shell.execute_reply":"2022-12-08T16:36:43.192251Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"def test_sanity_check():\n\n    x = Value(-4.0)\n    z = 2 * x + 2 + x\n  \n    q = z.relu() + z * x\n    h = (z * z).relu()\n    y = h + q + q * x\n    y.backward()\n    xmg, ymg = x, y\n\n    x = torch.Tensor([-4.0]).double()\n    x.requires_grad = True\n    z = 2 * x + 2 + x\n    q = z.relu() + z * x\n    h = (z * z).relu()\n    y = h + q + q * x\n    y.backward()\n    xpt, ypt = x, y\n\n    \n    # forward pass went well\n    assert ymg.data == ypt.data.item()\n    # backward pass went well\n    print(xmg, xpt, xpt.grad)\n    assert xmg.grad == xpt.grad.item()\n\n\ndef test_more_ops():\n\n    a = Value(-4.0)\n    b = Value(2.0)\n    c = a + b\n    d = a * b + b**3\n    c += c + 1\n    c += 1 + c + (-a)\n    d += d * 2 + (b + a).relu()\n    d += 3 * d + (b - a).relu()\n    e = c - d\n    f = e**2\n    g = f / 2.0\n    g += 10.0 / f\n    g.backward()\n    amg, bmg, gmg = a, b, g\n\n    a = torch.Tensor([-4.0]).double()\n    b = torch.Tensor([2.0]).double()\n    a.requires_grad = True\n    b.requires_grad = True\n    c = a + b\n    d = a * b + b**3\n    c = c + c + 1\n    c = c + 1 + c + (-a)\n    d = d + d * 2 + (b + a).relu()\n    d = d + 3 * d + (b - a).relu()\n    e = c - d\n    f = e**2\n    g = f / 2.0\n    g = g + 10.0 / f\n    g.backward()\n    apt, bpt, gpt = a, b, g\n\n    tol = 1e-6\n    # forward pass went well\n    assert abs(gmg.data - gpt.data.item()) < tol\n    # backward pass went well\n    assert abs(amg.grad - apt.grad.item()) < tol\n    assert abs(bmg.grad - bpt.grad.item()) < tol","metadata":{"id":"vY7OzWjuUiaa","execution":{"iopub.status.busy":"2022-12-08T16:36:31.362458Z","iopub.execute_input":"2022-12-08T16:36:31.362802Z","iopub.status.idle":"2022-12-08T16:36:31.377284Z","shell.execute_reply.started":"2022-12-08T16:36:31.362773Z","shell.execute_reply":"2022-12-08T16:36:31.376196Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"a = Value(-4.0)\nb = Value(2.0)\nd = Value(3.0)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LgTiYeZ-WGk","outputId":"a334fd44-c71e-4f4e-ce44-301e90d1d03e","execution":{"iopub.status.busy":"2022-12-08T16:36:33.095130Z","iopub.execute_input":"2022-12-08T16:36:33.095545Z","iopub.status.idle":"2022-12-08T16:36:33.103936Z","shell.execute_reply.started":"2022-12-08T16:36:33.095511Z","shell.execute_reply":"2022-12-08T16:36:33.102798Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"c = a + b\ne = c * d\ne.backward()","metadata":{"id":"Y0svSAs2h0Ap","execution":{"iopub.status.busy":"2022-12-08T16:36:33.716770Z","iopub.execute_input":"2022-12-08T16:36:33.717312Z","iopub.status.idle":"2022-12-08T16:36:33.722739Z","shell.execute_reply.started":"2022-12-08T16:36:33.717270Z","shell.execute_reply":"2022-12-08T16:36:33.721707Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"test_sanity_check()","metadata":{"id":"w9n8DN6RYkrx","execution":{"iopub.status.busy":"2022-12-08T16:36:34.866380Z","iopub.execute_input":"2022-12-08T16:36:34.866751Z","iopub.status.idle":"2022-12-08T16:36:34.890964Z","shell.execute_reply.started":"2022-12-08T16:36:34.866719Z","shell.execute_reply":"2022-12-08T16:36:34.889690Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"Value(data=-4.0, grad=-9) tensor([-4.], dtype=torch.float64, requires_grad=True) tensor([46.], dtype=torch.float64)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_22/1829826787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_22/4039265295.py\u001b[0m in \u001b[0;36mtest_sanity_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# backward pass went well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mxmg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mxpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: "],"ename":"AssertionError","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"test_more_ops()","metadata":{"id":"1T198QDQYh_q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Обучение на основе собственной бибилотеки","metadata":{"id":"o-KbDOhMYHZ1"}},{"cell_type":"markdown","source":"## Многослойный перцептрон на основе класса Value","metadata":{"id":"uVK1JLXom0Ze"}},{"cell_type":"code","source":"import random\n\nclass Module:\n\n    def zero_grad(self):\n        ...\n\n    def parameters(self):\n        return []\n\nclass Neuron(Module):\n\n    def __init__(self, nin, nonlin=True):\n        self.w = ...\n        self.b = ...\n        self.nonlin = nonlin\n\n    def __call__(self, x):\n        act = ...\n        return ...\n\n    def parameters(self):\n        return ...\n\n    def __repr__(self):\n        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"\n\nclass Layer(Module):\n\n    def __init__(self, nin, nout, **kwargs):\n        self.neurons = ...\n\n    def __call__(self, x):\n        out = ...\n        return out[0] if len(out) == 1 else out\n\n    def parameters(self):\n        return ...\n\n    def __repr__(self):\n        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n\nclass MLP(Module):\n\n    def __init__(self, nin, nouts):\n        sz = ...\n        self.layers = [Layer(sz[i], sz[i+1], nonlin=(i!=len(nouts)-1)) for i in range(len(nouts))]\n        \n    def __call__(self, x):\n        ...\n        return x\n\n    def parameters(self):\n        return ...\n\n    def __repr__(self):\n        repr = '\\n'.join(str(layer) for layer in self.layers)\n        return f\"MLP of [{repr}]\"","metadata":{"id":"rkl70dxhkcQN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение многослойного перцептрона","metadata":{"id":"YkkaE1V1m5i5"}},{"cell_type":"markdown","source":"Сам перцептрон","metadata":{"id":"WWy-H8eCn2zm"}},{"cell_type":"code","source":"nn = MLP(3, [4, 4, 1])\nprint(model)\nprint(\"number of parameters\", len(model.parameters()))","metadata":{"id":"3La6nRi4m920"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Набор данных","metadata":{"id":"OvkZVOLcnvqu"}},{"cell_type":"code","source":"xs = [\n  [2.0, 3.0, -1.0],\n  [3.0, -1.0, 0.5],\n  [0.5, 1.0, 1.0],\n  [1.0, 1.0, -1.0],\n]\nys = [1.0, -1.0, -1.0, 1.0] # desired targets","metadata":{"id":"aLJULsNanpVC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(20):\n\n    # forward\n    ...\n\n    # calculate loss (mean square error)\n    ...\n    \n    # backward (zero_grad + backward)\n    ...\n    \n    # update\n    learning_rate = ...\n    for p in n.parameters():\n        ...\n    \n    if k % 1 == 0:\n        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")","metadata":{"id":"OuCTaTB8n5l0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Домашнее задание","metadata":{"id":"n4maaWL5yg-f"}},{"cell_type":"markdown","source":"**Домашнее задание 1.** Доделать практику. Оформить код в три отдельных модуля `autograd`, `nn`, `train`","metadata":{"id":"2yyK39RYo084"}},{"cell_type":"markdown","source":"**Домашнее задание 2 (Опционально).** Создать свою функцию softmax, наследуемую от `torch.autograd.Function` и имплементировать forward и backward проход. Сравнить со стандартной функцией в Pytorch. \n[Создание функций](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html) [Софтмакс](https://congyuzhou.medium.com/softmax-3408fb42d55a)","metadata":{"id":"FdzPyQ-hylKH"}},{"cell_type":"code","source":"# Ваш код","metadata":{"id":"bGMpj9Pf61n2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Домашнее задание 3 (Опционально).** Добавить функцию софтмакс в собственну библиотеку автоматического дифференцирования. Сравнить с пунктом 2","metadata":{"id":"3VPpRO6H6SHF"}},{"cell_type":"code","source":"# Ваш код","metadata":{"id":"2YJfxtqSphFs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Домашнее задание 4 (Опционально).** Добавить визуализацию обучения. Потом мы пройдем более подробно.","metadata":{"id":"nRRgw0HNsr_a"}},{"cell_type":"markdown","source":"https://docs.wandb.ai/guides/integrations/pytorch","metadata":{"id":"W5AWW52REfn5"}},{"cell_type":"markdown","source":"https://docs.wandb.ai/ref/python/watch  ","metadata":{"id":"ekFfy3cWVOIW"}},{"cell_type":"markdown","source":"https://docs.wandb.ai/guides/track/jupyter","metadata":{"id":"9G4SOp28ok0o"}},{"cell_type":"code","source":"!pip install wandb","metadata":{"id":"lumiR8oykL04"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wandb login","metadata":{"id":"Xw3c6P7BkP9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nrun = wandb.init(project=\"polynom_learning_\")","metadata":{"id":"udPv0ufwkxOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run.finish()","metadata":{"id":"Xtpc9MAUodNs"},"execution_count":null,"outputs":[]}]}